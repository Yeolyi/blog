
## 개요

> This course introduces architecture of digital systems, emphasizing structural principles common to a wide range of technologies. It covers the topics including multilevel implementation strategies, definition of new primitives (e.g., gates, instructions, procedures, processes) and their mechanization using lower-level elements. It also includes analysis of potential concurrency, precedence constraints and performance measures, pipelined and multidimensional systems, instruction set design issues and architectural support for contemporary software structures.

[ocw.mit.edu](https://ocw.mit.edu/courses/6-004-computation-structures-spring-2017/)

[computationstructures.org](https://computationstructures.org/index.html)

[필기 백업 레포](https://github.com/Yeolyi/Computation_Structures)

챕터별 단원은 홈페이지에서 비디오를 나눈 것을 참고했다. 강의 비디오는 lecture note에 모든 내용이 있는 것 같아 굳이 보지 않았다.

## 1. Basics of Information

뚝딱뚝딱하려면 정보를 잘 표현하는 engineering tool이 필요하다.

### Information

> Information: Data communicated or received that resolves uncertainty about a particular fact or circumstance.

불확실성을 많이 해소시킬수록 데이터가 전달한 정보량이 많다.

이산 랜덤 변수 X의 가능한 값들인 x_i와 각각의 확률 p_i가 있을 때 x_i를 알았을 때의 정보량 I(x_i) = log2(1/p_i) bits. 1/p_i는 x_i의 uncertainty에 비례한다.

덱에서 하트인걸 알았으면 log2(1/(13/52)) = 2bits. 4개의 suit중에서 하나 특정지으려면 2비트니까 맞음.

### Entropy

나중에 배울 인코딩의 효율성을 측정하는 방법. 엔트로피 값에 가까울 수록 효율적인 인코딩이다. 엔트로피보다 작을 수는 없음.

> Entropy H(X) is the average amount of information contained in each piece of data received about the value of X.

H(X) = E(I(X)) = i=1~N sigma p_i \* log2(1/p_i)

### Encoding

> An encoding is an unambigouous mapping between bit strings and the set of possible data.

fixed-length encoding / variable-length encoding

심벌이 다른 확률로 출현하는 경우 variable-length 인코딩을 잘 하면 효율적인 인코딩이 가능하다.

모호하지 않은 인코딩을 이진 트리로 표현할 수 있다. 잎 노드가 각 심벌이 된다. 잎 노드까지의 경로는 포함 관계가 불가능해서 그런걸까?

모든 경우의 확률이 같다면 fixed-length 인코딩. 이진 트리에서 잎 노드의 깊이가 모두 같다. N번째 심벌의 random access가 가능하다! 엔트로피는 log2(N).

양수 인코딩하는건 아니까 생략. 4자리씩 묶어서 16진수로 표현하는 것도 생략.

MSB를 부호 비트로 사용하는 signed magnitude는 0을 표현하는게 두 개고 덧뺄셈의 로직이 다르다는 문제점이 있다.

Two's Complement 인코딩에서는 MSB가 -2^(n-1)이다. B - A = B + (-A)이고 A + (-A) = 0 = 1 + -1에서 -A = (-1 - A) + 1 = ~A + 1이다. 그런데 이런 증명은 덧셈이 되는걸 증명해야 의미있는거 아닌가?? -1 + 1 = 0 인걸로 증명한건가? **증명 방법 생각해보기.**

Variable-length encoding에서 확률 높은 애를 짧게, 낮은 애를 길게 해서 효율적으로 할 수 있다.

### Huffman's Algorithm

> Huffman’s Algorithm tells us how to construct an optimal variable-length encoding. By “optimal” we mean that, assuming we’re encoding each symbol one-at-a-time, no other variable-length code will have a shorter expected length.

남은 심벌과 이미 만들어진 트리의 부모들 중에서 가장 확률이 낮은 두 개를 골라 합치기를 반복한다.

얘보다 잘하려면 sequences of choices로 묶어서 인코딩해야한다. 많은 파일 압축 알고리즘이 이렇게 함.

Modern file compression algorithms use an adaptive algorithm to determine on-the-fly which sequences occur frequently and hence should have short encodings. They work quite well when the data has many repeating sequences, e.g., natural language data where some letter combinations or even whole words occur again and again. [LZW](https://en.wikipedia.org/wiki/Lempel–Ziv–Welch)

### Error Detection and Correction

> Hamming Distance: The number of positions in which the corresponding digits differ in two encodings of the same length.

인코딩이 어떻게 달라졌는지 표현하는게 유용하다.

두 유효한 code word인 0과 1의 해밍 거리가 1이기에 단일-비트 에러가 나도 유효한 결과물이 나오는 것이 문제이다.

Parity 비트를 전체 1의 개수가 even하도록 더해(even parity) min HD(code words + parity) = 2이도록 한다. 이후 1의 개수를 세 에러의 유무를 알 수 있다. 비트끼리 더해 모듈러2를 하거나 **XOR**를 하면 된다. 그래도 odd개의 에러가 나면 잡을 수 없다. Parity는 단일 에러를 잡는데만 유용하다.

E개의 에러를 감지하려면 각 부호간에 최소 해밍 거리가 E+1이어야한다. 그렇지 않으면 다른 유효한 부호로 바뀌게 된다.

E개의 에러를 고치려면 각 부호간에 최소 해밍 거리가 2E+1이어야 한다. 최대 에러의 개수가 E개임을 가정하면 올바르게 correction할 수 있다.

> Coding theory is a research area devoted to developing algorithms to generate code words that have the necessary error detection and correction properties.

### WorkSheet

9페이지 O 문제는 아직도 모르겠음.

4-C. min HD임이 중요. 보편적인 현상인지는 모르겠는데 00000에서 11111으로 가는 길에 다른 애가 있음. HD의 영역?이 분리된 경우는 없을까. min따로 max따로일 수 있게.

## 2. The Digital Abstraction

### 정보의 표현

비트를 위한 물리적인 representation을 찾아보자. 접근, 변형, 전송, 저장이 용이해야한다.

전압을 통해 비트를 표현해보자. 예를 들어 0V면 0, 1V면 1. 전기는 값싸고 믿을만하며 배터리로 공급할 수 있다. 전압과 전류에 대한 공학적인 시식도 축적되어있고 안정된 상태에서는 zero power dissipation이 가능하다. 다만 주변의 전자기장의 영향을 받고 와이어의 전압을 바꾸는 것은 시간이 소모된다. 현대에는 이러한 RC time?이 작지만 0은 아니다. 아무튼 이후 수업에서는 전압을 사용한다.

N비트로 표현할 수 있는 정보량을 표현하려면 0V에서 1V까지 2^N개로 쪼갤 수 있어야한다. 이처럼 전압을 통한 정보의 인코딩은 전압을 구분할 수 있는 능력에 한정된다.

사진을 인코딩한다고 생각해보자. 미리 정의된 경로로 이미지를 스캔해서 전압의 그래프를 얻어낸다. Continuous waveform라 하며 옛날 텔레비전의 작동 방식이다.

Information Processing = Computation. Pre-packaged block을 사용하여 시스템을 예측 가능하게 설계할 수 있다. 위에서 만든 전압 그래프에 Copy가 Inv따위의 연산을 적용시킬 수 있다.

하지만 현실적으로 노이즈와 부정확함은 피할 수 없다. 에러는 block을 지남에 따라 쌓이게 된다. 무한한 범위의 정보를 재생산하는 것은 불가능하다. Copy와 Inv를 반복하면 이미지는 흐릿해질 것이다.

### The Digital Abstraction

> To solve our engineering problem, we will introduce what we'll call the **digital abstaction**. The key insight is to use the continuouse world of voltages to represent some small, finite set of values.

Threshold voltage인 V_L과 V_H를 설정해 L보다 작으면 0, 크면 H로 하자. 그 사이는 forbidden zone으로 어떤 값인지 판단하지 않는다. V_L 아래의 전압과 V_H 위의 전압에 대해서만 올바르게 동작하면 된다.

### Combinational device

> Combinational device는 하나 이상의 입/출력, 모든 유효한 입력의 조합에 따른 출력의 명세, device가 유효한 입력으로부터 출력을 계산하는데 필요한 시간의 상한인 t_PD를 가지는 circuit element이다.

위 네가지 기준을 static discipline이라 하며 모든 조합 논리 회로가 충족시켜야한다.

조합 논리 컴포넌트로부터 더 큰 조합 논리 시스템을 만드려면 각각의 컴포넌트가 조합 논리려야하고 각 컴포넌트의 입력이 다른 컴포넌트의 출력이거나, 상수 전압이거나, 시스템 입력이어햐하고 루프가 없어야한다. 즉, 경로에 컴포넌트가 단 한번만 등장해야한다.

In general, since there are no cycles in the circuit, we can determine the value of every internal signal by evaluating the behavior of the combinational components

따라서 여러 조합 논리 회로들을 composite하여 임의의 복잡도를 지닌 조합 논리 회로를 만들 수 있다.

입력과 출력의 bound가 같으면 출력이 유효한 입력이 되지 않을 확률이 크다. 출력을 입력보다 타이트하게 잡아야한다. 즉 V_OL보다 V_IL이 크고, V_IH보다 V_OH이 크다. 두 갭을 noise margins라 하고 이중에 작은 것을 noise immunity라 한다.

Voltage Transfer Characteristic(VTC)는 안정된 상태에서 V_in에 따른 V_out을 보여준다. 장치가 얼마나 빠른지는 안알려줌 주의, dynamic behavior가 아닌 static behavior를 보여준다. Static discipline에 따라 VTC는 valid input에 invalid output인 영역을 피해야한다. Forbidden zones라고도 부름.

V_OH - V_OL > V_IH - V_IL이므로 VTC의 가운데 영역은 위로 길쭉하다. 추가로 출력을 다른 장치의 입력으로 넣으려면 V_in과 V_out의 범위가 같아야하고 VTC가 정사각형이어야한다. 따라서 조합 장치는 반드시 GAIN > 1이고 nonlinear하다.

> In electronics, gain is a measure of the ability of a two-port circuit (often an amplifier) to increase the power or amplitude of a signal from the input to the output port by adding energy converted from some power supply to the signal.

### Worksheet

- Analog: each processing step accumulates noise
- Digital: each processing step restores output to a valid digital level

6-b??

## 3. CMOS Technology

MOSFET의 물리적인 내용은 우선순위가 높지 않다고 생각하여 생략. 후에 문제에서도 안나온다. 왜 NFET이 pulldown인지 이해하려면 알아야되기는 한 듯.

MOSFET의 Voltage-controlled switch로서의 기능에 집중해보자.

NFET은 1이면 닫힌다. PFET은 1이면 열린다. PFET에 점이 있다.

NFET와 PFET을 상호보완적으로 사용해서 CMOS(complementary MOS) logic familiy를 만들 수 있다. 전자는 pulldown circuit에만, 후자는 pullup circuit에만 사용한다. 그 이유는 뒤에서.

V_DD = power supply voltage.

Complementary refers to property that when one of the circuits is conducting, the other is not. Pullup 회로끼리, Pulldown 회로끼리 모으고 둘을 반대이다. nfet과 pfet, 병렬과 직렬.

하지만 모든 논리 함수에 적용할 수 있는 방법은 아닌데, CMOS gate에서 rising input(0 -> 1)은 반드시 falling output이 되어야하기 때문이다. NFET은 1이면 groud에 연결되고, PFET은 1이면 V_DD에서 연결이 끊긴다. Falling output이라는건 변화가 일어난다면 falling이라는 뜻인듯? 따라서 positive logic은 CMOS를 통해 구현할 수 없다.

> Propagation delay(t_PD): An UPPER BOUND on the delay from valid inputs to valid outputs.

> Contamination delay(t_CD): A LOWER BOUND on the delay from an invalid input to an invalid output.

t_PD보다 짧은건 괜찮고 t_CD보다 긴건 괜찮다는 느낌.

> Lenient Combinational Device: Output guaranteed to be valid when any combination of inputs sufficient to determine the output value has been valid for t_PD.

Lenient behavior를 X를 통해 진리표에 표현할 수 있다.

완벽한 VTC는 높은 gain과 V_OH = V_DD, V_OL = GND이며 높은 노이즈 margin과 static power dissipation이 없음을 의미한다.

### Labs

In the manufacturing process we're modeling, n-channel MOSFETs have much better conductance than p-channel MOSFETs

By sizing the MOSFETs so that the VTC is centered, we maximize the noise immunity of the inverter.

milli: 10^-3, micro: 10^-6, nano: 10^-9, pico: 10^-12

전자기학 공부 해야되긴 하겠다^^,, GND 이런거 원리 잘 모르겠음.

NFET는 V_GS가 V_TH보다 작거나 같을 때 off이다. When in is at 3V and the NFET's source node out1 reaches 2.5V, the NFET turns off and the source node voltage can raise no higher. This is why we don't use PFETs in pulldown circuits or NFETs in pullup circuits — in that configuration we observe threshold drops in the max and min output voltages, which accumulate and cause the buffers to produce meaningless outputs.

PFET은 기본값이 흘리는거고 뭐가됐든 들어온대로 내보내니까 pulldown으로 쓰면 괜찮다는건가?

Note that it is possible to design a gate where the pulldown and pullup circuitry is not complementary and still pass the tests! This happens because an NFET is much "stronger" than a PFET with the same width. Of course, in the buggy circuit, when both the pulldown and pullup are conducting, there's basically short between power and ground, and a lot of power is dissipated

## 4. Combinational Logic

### Sum of products

모든 조합 장치는 진리표 혹은 AND, OR, NOT으로 구성된 sum-of-product 불리언 표현식으로 나타낼 수 있다.

진리표에서 sum-of-products 불식을, 불식에서 회로로 기계적으로 바꿀 수 있다!

[불리언 vs 부울 vs 불](https://www.facebook.com/gbitbook/posts/781435735382876/)

### Useful Logic Gates

Sum-of-product는 여러개의 인풋을 받는 AND와 OR 게이트가 필요하다. 불 연산의 associative property를 활용한다.

체인 형태로 연결하는 것과 트리 형태로 연결하는 것 모두 같은 양의 컴포넌트를 사용한다?! 다만 전자는 propagation delay가 리니어하게, 후자는 logarithmic하게 증가한다. 하지만 하나의 인풋이 바뀌었을 때는 체인이 빠른 경우가 있다.

CMOS는 rising input이 falling output이 되므로 NAND와 NOR을 사용한다. 얘네들은 associative하지 않아 체인이나 트리 형태로 엮을 수 없다.

XOR는 parity, arithmetic logic을 구현하는데 유용하다. Programmable inverter로도 사용됨. 얘는 엮을 수 있다.

모든 논리 함수는 NAND만을 사용해서 구현할 수 있다.

### Inverting Logic

빠르길 원하면 inverting gates, 작길 원하면 non-inverting gates를 사용한다.

느린 게이트를 사용해도 괜찮은 경우가 있다. Propagation delay는 딜레이가 가장 큰 경로에 좌우되기 때문에 나머지 짧은 경로에 있는 컴포넌트는 작고 느린 것을 써도 괜찮다. 작은 width를 가진 MOSFET을 사용하면 느려진다.

4-input gates에서 더 가면 conducting channel의 저항이 커지는 등 좋지 않다. 따라서 그 이상은 NAND와 NOR을 조합해서 만들자.

Loading on the inputs도 고려 대상이다. 많은 MOSFET에 연결되어있을수록 capacitive load가 커진다.

### Logic Simplification

불식을 간단하게 만들어 더 적은 게이트를 사용할 수 있다.

> [Quine–McCluskey algorithm](https://en.wikipedia.org/wiki/Quine–McCluskey_algorithm). Although more practical than Karnaugh mapping when dealing with more than four variables, the Quine–McCluskey algorithm also has a limited range of use since the problem it solves is NP-complete.

진리표에 don't-care를 반영하여 최적화의 여지를 드러낼 수 있다.

무조건 논리식이 단순하다고 좋지는 않은데, 일시적으로 비트가 바뀌는 glitch이 생길 수 있고 이는 에너지를 소모하기 때문이다. 따라서 회로를 lenient하게 유지하기 위해서 추가적인 게이트를 사용할 수 있다.

### Karnaugh Maps

> K-Map: a truth table arranged so that terms which differ by exactly one variable are adjacent to one another so we can see potential reductions easily.

일반적으로 이진수를 세는 방법과 다른데, Gray Code라고 불리는 방식은 인접한 라벨은 비트가 1개씩만 다르다.

3변수, 4변수는 각각 바뀔 수 있는 자릿수가 3개, 4개이고 2차원(상하좌우) 종이에 표현 가능하다. 그 이상은 3차원으로 가야하고 그 이상은 쉽지 않다.

> Prime implicant: Implicant which is not completely contained in any other implicant. 폭과 높이가 2의 지수배여야한다. 그래야 dont-care 변수들?을 쳐낼 수 있다.

최종 표현식은 prime implicant들로 구성된다. 그리디하게 구할 수 있다?

구현을 lenient하게 하려면 모든 prime implicant들을 포함시키면 된다.

### Multiplexers

Multiplexer(MUX)는 여러 입력중에서 하나를 선택해 출력으로 내보낸다.

MUX의 입력에 상수값을, 선택자?에 입력을 넣음으로서 임의의 논리 회로를 구현할 수 있다. 재설계도 편하다. MUX 입력이 꼭 상수일 필요는 없는데, XOR를 2-input MUX로 구현해보자.

MUX는 하나의 출력 칼럼이 있을 때 유용하고, 여러개의 출력 칼럼이 있으면 ROM을 사용한다. ROM의 주요 구성요소인 decoder는 k비트의 select 입력을 받아 2^k개의 출력 중 하나를 1로 만든다. 기본적으로 VDD에 연결되어있고, 1이어야 하는 경우면 NFET이 ground에 연결되어있어 VDD를 흘려내보낸다. The column circuitry is designed so that if no pulldown switches force its value to 0, its value will be a 1. Think of the decoder outputs as indicating which row of the truth table has been selected by the input values.

입력이 커지면 ROM도 느려질텐데, 일부 입력을 column들의 selector로 하여 속도를 향상시킬 수 있다. 이는 ROM, RAM, logic array등에 자주 활용된다.

As the decoder lines cycle, the output values may change several times until the final configuration of the pulldown switches is stable. So ROMs are not lenient and the outputs may show the glitchy behavior discussed earlier??? 디코더 구현을 어떻게 하길래?? Cycle이라는게 1의 위치가 바뀌는걸 의미하는건가.

### Worksheet

> A universal gate is a gate which can implement any Boolean function without need to use any other gate type.

### Labs

Measuring a particular CMOS device G, we find 1.5V noise margins. If the width of all mosfets inside of G were doubled, we would expect the noise margins of the new gate to...

XOR의 효과적인 구현은 기억해두면 좋을 듯!

Adder는 일단 작동만 되는 상태. 더 빠르고 noise margin 넓고 갑싼 구현은 나중에 돌아와서 해보기.

## 5. Sequential Logic

지금까지 배운걸로는 상태를 기억해야되거나 이벤트(버튼을 누르는 등. 시간 개념이 끼어든다.)에 의해 출력이 바뀌는 회로는 만들 수 없다.

### Digital State

상태를 저장하는 순차회로를 만든다. 조합회로에 메모리에 저장된 현재 상태와 입력값이 들어가고 다음 상태와 출력이 나온다.

메모리 컴포넌트에는 LOAD control signal과 data가 들어간다.

> Circuits that include both combinational logic and memory components are called sequential logic.

축전기를 사용한 방법에서는 bit line을 원하는 값으로 맞춰놓고 word line을 HIGH로 하면 축전기가 그에 맞게 변한다. 이후 word line을 low로 하면 상태가 저장된다. 저장된거에 접근하고싶으면 bit line을 중간값으로 하고 word line을 HIGH로 한다. 변화가 작아 sense amp를 사용한다.

이러한 DRAM은 비트당 가격이 작지만 접근 속도가 느리고 구현이 복잡하다. 전류가 조금씩 누출되기에 주기적인 refresh가 필요하다.

[SRAM vs DRAM](https://www.enterprisestorageforum.com/hardware/sram-vs-dram/)

Inverter 두 개를 이어 bi-stable storage element를 만들 수 있다.

### D Latch

이를 연장시켜 MUX를 활용하면 settable memory element(Latch)를 만들 수 있다. Gate 입력이 0이면 루프를 통해 이전 값이 재사용되어 이전에 말한 bi-stable storage element가 된다. 1이면 D1 입력에 따라 출력이 결정된다. 사이클이 있으므로 더이상 조합 회로가 아니다. Q의 출력이 안정적이어질 때까지 Gate를 충분한 시간 1로 하고 이후 0으로 바꾸면 정보가 저장된다.

이러한 메모리 디바이스를 D latch라 한다.

그런데 t_CD에서 t_PD동안은 출력을 보장할 수 없는데 이 출력을 입력으로 사용하는 회로가 작동할 수 있는걸까? G가 바뀌는 동안, D가 바뀌는 동안 출력이 불안정하면 어떡하지?

Lenient한 MUX를 사용하면 된다. 아래 내용 잘 와닿지 않으니 나중에 또 보기. 아래 규칙을 보면 이해가 조금 된다.

1. G가 1일 때 D가 t_PD동안 stable했다면 Q의 초기값과 상관없이 Q는 안정적으로 D와 같다.
2. Q와 D가 t_PD동안 안정적이고 같은 값이었으면 Q는 G의 변화에 영향을 받지 않는다. -> Q를 오염시키지 않고 G를 1에서 0으로 바꿀 수 있다.
3. G가 0이고 Q가 t_PD동안 안정적이었으면 Q는 D의 변화에 영향받지 않는다.

이래도 D와 G가 동시에 바뀌면 골치아프니 규칙이 필요하다.

1. G가 1일 때 D를 원하는 값으로 설정. t_PD가 지나면 위에 1번에 따라 Q가 D와 같아진다.
2. t_PD동안 Q'가 래치의 안으로 잘 흐르도록 기다린다. 위에 2번에 따라 G는 무관해진다. 이 2\*t_PD 시간을 setup time of the latch라 한다.
3. G를 0으로 맞춘다. G가 흐르는 t_PD이후 3번에 따라 Q와 D는 무관해진다. 이 t_PD를 hold time of the latch라 한다. G의 변화 이후 D가 안정적이어야하는 시간.

이러한 setup/hold time 요구사항을 dynamic discipline이라 한다.

### D Register

이런 설계면 G가 너무 오랫동안 1이면 출력이 Combinational Logic을 지나고 feedback loop를 만들게 된다. 따라서 G가 1인 시간은 dynamic discipline을 만족시킬 정도로 길어야하지만 새로운 상태 정보가 다시 combinational logic을 지나갈 정도로 길면 안된다. 너무 빡세다.

게이트 두 개를 사용해서 한 번에 하나만 열려있게 해보자.

D register라 한다. 여기서 load signal을 주로 clock이라 부른다. Master latch와 slave latch가 이어져있고 각각은 상반된 clk 상태에 열린다.

Register를 flip-flop이라 부르기도 한다. [Difference between flip-flop and latch](https://www.geeksforgeeks.org/difference-between-flip-flop-and-latch/).

### D Register Timing

CLK이 0->1로갈 때의 D를 다음 클럭 엣지까지 저장한다. 상승엣지에서 출력이 바뀌므로 positive-edge-triggered D register라고 한다.

마스터 래치에서 슬레이브 래치로 보내주는 신호는 dynamic discipline(setup/hold times)을 따라야한다. Master latch contamination delay >= slave latch hold time.

Setup/hold와 별개로 레지스터도 t_pd와 t_cd를 가진다. 얘네는 클럭의 상승 엣지에 상대적으로 정해진다. 레지스터는 lenient하기 때문에 t_pd와 t_cd는 Q가 바뀔 때만 적용된다.

레지스터의 master latch의 스펙에 따라 레지스터의 t_setup과 t_hold가 정해진다.

### Sequential Circuit Timing

이 강의에서는 single-clock synchronous circuits를 사용한다.

- 레지스터의 입력과 출력간에 combinational path가 없어야한다. (자료 사진엔 우측 하단에 있는 것 같은데??). 따라서 시스템 입력과 레지스터 출력은 같은 combinational block을 두 번 지나지 않는다.
- 하나의 클럭이 공유된다.

이런 설계에서는 t_PD의 최대값에 레지스터의 setup 시간을 더한 것보다 큰 클럭 주기를 선택해 dynamic discipline을 따름을 보장할 수 있다.

> t_CD,reg1 + t_CD,L >= t_HOLD,reg2

> t_PD,reg1 + t_PD,L + t_SETUP,reg2 <= t_CLK

시프트 레지스터처럼 레지스터 사이에 combinational logic이 없으면? 첫번째 식에 따르면 t_CD,reg1 >= t_HOLD,reg2여야한다. 일반적으로 contamination delay가 hold time보다 작으니 좋지 않다. 이 경우 더미 로직을 넣음.

> Clock skew: Clock signal arrives at one register before it arrives at the other.

Clock skew가 있는 경우 여유를 둬야하기에 downstream register의 setup/hold time을 늘린다.

칩 설계가 같아도 수율에 따라 t_PD가 달라 클럭 속도가 다를 수 있다.

> t_S,INPUT = t_PD_L + t_S,R

> t_H,INPUT = t_H,R - t_CD,L

-> CD는 빠르고 PD는 느리기에 들어간 시간 범위와 나온 시간 범위가 다르다.

[SR Latch](http://www.ktword.co.kr/test/view/view.php?m_temp1=4234&id=1432), [D Latch](http://www.ktword.co.kr/test/view/view.php?m_temp1=5300).

### Worksheet

그런데 래치 분석할 때 t_PD로 전부 때문건 간단하게 하려고 그런건가? D의 경로와 Q'의 경로가 다를 수 있는거 아닌가.

CLK의 분석에 in은 무시해도 되는듯.

T flip flop: T가 1일 때 Q를 토글한다.

## 6. Finite State Machines

### Finite state machines

상태가 k비트, 입력이 m비트, 출력이 n비트면 조합 회로는 2^(k+m)개의 행과 k+n개의 열을 가지는 진리표로 나타낼 수 있다.

0110이 입력되면 열리는 순차 회로에서 꼭 최근 4개의 입력을 저장할 필요는 없다. We only need to know if the most recent entries represent some part of a partially-entered correct combination.

FCM 추상화의 목적은 구현에 상관없이 순차 회로의 입출력 behavior를 설명하는 것이다.

상태를 나타내는 비트수와 조합 논리의 복잡도간에 트레이드오프가 있다. 또한 입력을 한번에 받을건지 나눠서 받을건지, 출력을 한번에 줄건지 나눠서 줄건지의 트레이드오프도 있다.

### State transition diagrams

무어 머신은 출력이 상태와 관련되어있고 밀리 머신은 출력이 상태와 입력에 관련되어있다. 밀리 머신의 다이어그램에서 출력은 화살표에 표기한다.

그럼 밀리 머신은 입력이 안정적이어야 출력도 잘 나오는건가? 입력을 따로 레지스터에 저장해놓는건가? (아래에서 synchronizer에 대해 다룸.)

유효한 state diagram에서 화살표는 mutually exclusive(입력 당 하나)하고 collectively exhaustive(모든 가능한 입력을 포함)해야한다. 즉 모든 상태와 입력의 조합 당 하나의 transition이 있어야한다.

State transition diagram의 모든 정보는 진리표로 나타낼 수 있다. State의 인코딩에 따라 필요한 로직의 양을 크게 줄일 수 있다.

16 x 4 메모리는 4비트의 location이 16개 있다는 뜻이다. 이 경우 각 location은 진리표의 한 행을 나타내고 4비트는 진리표의 열을 나타낸다.

ROM을 사용한 구현에서는 invalid state가 될 문제도 있는데, 사용되지 않는 state들이 초기 state를 가리키도록 해도 된다.

### FSM states

K-state FCM의 모든 상태들은 k 미만의 step들로 도달할 수 있다. State의 개수의 상한을 알고 있으면 transition disgram을 블랙 박스?로부터 유추해낼 수 있다.

> We say that two FSMs are equivalent if and only if every input sequence yields identical output sequences from both FSMs.

### Roboant example

### Equivalent states; Implementation

[Maze solving algorithm](https://en.wikipedia.org/wiki/Maze-solving_algorithm#Wall_follower)

Physical behaviors that arise from simple interactions between component molecules can sometimes be more easily modeled using cellular automata — arrays of communicating FSMS — than by trying to solve the partial differential equations that model the constraints on the molecules’ behavior.

### Synchronization & metastability

비동기적인 입력을 받는 시스템, 입력의 변화가 clock과 무관한 시스템에서는 input을 synchronizer에 연결한다.

Synchronizer는 decision time인 t_D와 allowable error인 t_E로 표현된다. 클럭 앞 뒤로 t_E의 여백만 있으면 입력대로 출력이 바뀐다. t_E보다 짧으면 0또는 1을 stable하게 반환한다.

For no finite values of and can we build a synchronizer that’s guaranteed to meet this specification even when using components that are 100% reliable?? (뒤랑 이어지는 내용인듯.)

그냥 D-latch를 써서 구현해보면 input의 변화 시점에 따라 dynamic displine을 어기게 된다. MUX의 VTC와 v_in = v_out의 교점들을 보면 양단 빼고 가운데도 있다. IN과 CLK이 비슷한 시간대에 바뀌면 Q의 전압이 바뀌는 중이어서 이 가운데 교점에 머물게 될 수도 있다. 이 상태를 metastable state라 한다. 이 상태에 머물러 있는 시간의 bound를 알 수 없다.

Dynamic discipline을 위반하는 것은 레지스터가 digital output을 만들어낼 것을 일정 시간동안 보장하지 못함을 의미한다. 이때는 PFET와 NFET가 모두 conducting할 수 있으므로 power dissipation이 발생할 수도 있다.

Metastable 전압에 가까울수록 resolve하는데 걸리는 시간이 길어지는데, 가까운 정도의 하한은 없으므로 resolve되는 시간의 상한도 존재하지 않는다. 특정 시점 T에 metastable하다면 어떠한 유한 시간 이후에도 metastable할 가능성은 0이 아니다. 시간이 지날수록 exponential하게 감소하는건 다행. 더 궁금하면 [여기?](https://computationstructures.org/notes/arbitration/notes.html) 참고.

D-register에서 나올 수 있는 metastable한 값을 여러 d-register를 거치게 해서 quarantine함으로서 해결할 수 있다. 일단 metastable해도 두번째 레지스터로는 first half of the clock cycle동안은 도달하지 못하니까 괜찮다.

> The bottom line: we can use synchronizing registers to quarantine potentially metastable signals for some period of time. Since the probability of still being metastable decreases exponentially with the quarantine time, we can reduce the failure probability to any desired level. Not 100% guaranteed, but close enough that metastability is not a practical issue if we use our quarantine strategy.

### Labs

> ...an unlimited memory capacity obtained in the form of an infinite tape marked out into squares, on each of which a symbol could be printed. At any moment there is one symbol in the machine; it is called the scanned symbol. The machine can alter the scanned symbol and its behavior is in part determined by that symbol, but the symbols on the tape elsewhere do not affect the behavior of the machine. However, the tape can be moved back and forth through the machine, this being one of the elementary operations of the machine. Any symbol on the tape may therefore eventually have an innings. (Turing, 1948)

괄호 튜링 머신 생략.

JADE 과제는 비트 하나를 어떻게 빼오는지 모르겠어서 넘김 ㅠ

## 7. Performace Measures

회로의 성능을 측정한 기준과 성능을 개선할 방법을 알아보자.

### Latency & throughput

세탁기, 건조기 비유 - 건조기가 돌아가는 동안 세탁기가 일을 안하면 아깝다. 건조기가 돌아가는동안 세탁기도 일을 시키면 효율적이다. 이때 Total_PD = N \* max(Washer_PD, Dryer_PD)이다.

> Systems that overlap the processing of a sequence of inputs are called pipelined systems and each of the processing steps is called a stage of the pipeline. The rate at which inputs move through the pipeline is determined by the slowest pipeline stage.

> Latency: The delay from when an input is established until the output associated with that input becomes valid.

> Throughput: The rate at which inputs or outputs are processed.

일반적으로 파이프라인으로 throughput을 늘리면 latency가 늘어난다. 모든 파이프라인 단계가 lock-step으로? 작동하고 processing의 rate가 가장 느린 단계로 고정되기 때문이다.

### Pipelined circuits

레지스터로 조합 회로를 여러 단계로 쪼개고, 각 단계의 출력을 레지스터로 저장해 다음 단계의 입력으로 다음 사이클에 제공한다. 특정 입력은 한 사이클 당 한 단계씩 전진한다.

> A well-formed K-Stage Pipeline(K-pipeline) is an acyclic circuit having exactly K registers on every path from an input to an output.

K-State pipeline은 각 단계의 출력 부분에 레지스터가 있다는 관습을 채택하자. 또란 레지스터들이 공유하는 CLK 주기는 조합 회로의 PD, 입력 레지스터의 PD, 출력 레지스터의 t_setup의 합 이상이어야한다.

> The latency of a K-pipeline is K times the period of the system's clock.

> The throughput of a K-pipeline is the frequency of the clock.

### Pipeline methodology

선을 열심히 긋는다. 모든 출력을 지나는 선을 우선 긋고(위에서 말한 관습 관련인듯), 이후 병목을 일으키는 가장 느린 회로를 중심으로 선을 추가한다. 모든 선은 끝이 맞닿아있어야하며 이를 통해 모든 입출력 경로를 횡단?했음을 보장한다.

가장 느린 컴포넌트를 파이프라인으로 격리했으면 그 이상 throughput을 개선할 수는 없다. 하지만 느린 컴포넌트 내부를 파이프라인으로 구성하면 더 개선할 수도 있다. 건조기 예시처럼 파이프라이닝조차 못하는 경우는 다음 섹션에서 살펴보자.

### Circuit interleaving

컴포넌트 자체를 파이프라인화시키지 못해도, 2개의 파이프라인안된 컴포넌트를 interleaving하여 2-state pipeline과 같은 효과를 얻을 수 있다.

느린 컴포넌트 두 개의 입력을 두 개의 D-latch에서 제공하고, 각 latch의 G 입력은 0과 1을 오가는 FSM에서 제공한다. 출력또한 두 느린 컴포넌트의 출력들 중 하나를 FSM에서 골라온다.

여기는 pdf 사진 보는게 좋을 듯!

2\*t_CLK >= t_PD,upstreamREG + t_PD,LATCH + t_PC,C + t_PD,MUX + t_SETUP,REG

Upstream REG는 사진에 나와있지 않은, 외부에서 입력을 제공하는 레지스터인듯. t_PC,C는 오타인가?

Parallelism으로도 속도 향상할 수 있다고 그러는데 이거 그냥 여러개 합친거 아닌가,,,?

파이프라인 레지스터와 interleaving 컴포넌트들의 오버헤드가 가능한 클럭 주기의 상한을 결정한다. 무한한 속도 향상은 안됨!

### Self-timed circuits

지금까지 살펴본건 synchronous, globally timed system. 하지만 처리 시간이 데이터의 내용에 의존적이면 다른 방법이 필요하다. 아래 내용은 그림 보면서 이해하는게 좋을 것 같다.

Handshake protocol을 사용해 synchronous, locally timed system을 만들 수 있다.

Handshake protocol: HERE-IS-X 시그널을 보내고 다음 단계에서 GOT-X로 응답하는 것. 여전히 클럭이 있으므로 시그널 값들은 클럭의 상승 엣지에서만 평가된다. HERE-IS-X는 다음 상승 엣지부터 값을 전달할 수 있다는 뜻이고, GOT-X는 다음 상승 엣지에 다음 값을 받을 것이라는 뜻. 두 신호 모두가 한 클럭에 1이면 handshake가 끝나고 해당 클럭에 데이터가 교환된다?? 아 다음 상승 엣지부터 전달한다는게 각 시그널은 언제든 바뀔 수 있으니까 가장 인접한 클럭에 바꿀 수 있다는 뜻인듯. 클럭에 서로의 시그널을 읽는거지 그때만 시그널이 바뀌는건 아님!

Clock-free asynchronous self-timed system도 가능하다. **여기는 막막하니 나중에 다시 읽어보기.**

### Control structures

- Globally timed synchronous: 공통된 클럭으로 작동하는 FCM. 설계가 쉽지만 고정 간격 클럭이 비효율적일 수 있음.
- Globally timed asynchronous: 중앙 제어 유닛이 작업에 맞춰서 시간을 나눈다. 시스템이 커지면 timing generator를 만들기 너무 어렵다. 걍 쓰지 마,,
- Locally timed synchronous: 각각의 하위 시스템에서 글로벌 클럭과 동기된 시작과 끝 시그널을 만든다.독립적인 타이밍을 가지는 컴포넌트들로 큰 시스템을 만드는 가장 좋은 방법.
- Locally timed asynchronous: 각각의 하위 시스템이 비동기적인 시작과 끝 시그널?을 만든다. 최근 몇 년간 핫한 아이디어. 정수 나눗셈같은 특별한 경우에 열심히 설계할 가치가 있다. 데이터마다 처리 시간이 달라지기 때문.

### Worksheet

2-B를 보면 줄을 묶는 위치에 여러 선택권이 있는 것 같은데, 만약 output들을 지나는 최우측의 선이 오직 output만 지나야하는거면 선택지는 하나임. 그게 자연스러운 것 같은데 증명은 못하겠다,,, 5.C가 이거 못지켜서 틀렸었음.

k-파이프라인된 컴포넌트는 안에 k개의 레지스터가 있다고 생각하자. 출력이 2개면 출력쪽에 레지스터 두 개 있는거임. 컴포넌트 밖에 그리면 이상한듯.

## 8. Design Tradeoffs

디지털 시스템을 더 작고, 빠르고, 에너지 효율적으로 만들어보자. 모두를 높이기는 힘들고 설계상의 트레이드오프를 하게 된다. 그래픽카드와 전자시계 설계에서의 트레이드오프는 다르다.

### Power dissipation

Static power dissipation은 회로가 idle할 때 낭비되는 전력.

- Gate oxide의 두께와 관련된 것 하나. 너무 얇아져서 전자가 insulator를 건너갈 수 있게 되었다.
- Drain와 source를 지나가는 전류와 관련된 것 하나. Sub-threshold conduction이라 부른다. V_GS - V_TH에 지수적으로 비례하는데 V_TH가 점점 작아지니 conduction도 커진다.

**물리 관련이라서 생략...**

### Carry-select adders

Worksheet도 없고,,, 노잼이라서,,,

### Carry-lookahead adders

### Binary multiplication

### Multiplier tradeoffs

## 9. Instruction Set Architectures

파트 2 시작. Programmable architecture에 대해 공부해보자. 서로 다른 종류의 이진 데이터를 통해 유용한 연산을 할 수 있는 디지털 시스템을 설계해보자.

### Datapaths & FSMs

> 각 상태의 출력이 단순 불 연산보다 복잡해지면 high level FSM이라고 한다.

> A [datapath](https://en.wikipedia.org/wiki/Datapath) is a collection of functional units such as arithmetic logic units or multipliers that perform data processing operations, registers, and buses.

> The [control unit (CU)](https://en.wikipedia.org/wiki/Control_unit) is a component of a computer's central processing unit (CPU) that directs the operation of the processor.

### Programmable Datapaths

지금까지 특정 연산을 위한 하드웨어를 설계하는 법을 배웠다. FSM을 위한 state transition diagram을 그리고, 레지스터와 조합 논리를 사용해 적합한 datapath를 추가한 뒤, datapath에 필요한 control signal을 만들어내는 FSM을 추가헀다.

Datapath에 있는 레지스터를 포함해서 진리표를 그리면 너무 켜져서 답이 없어진다. 그래서 control FSM과는 분리함.

Control FSM을 설계하는 것을 datapath를 프로그래밍하는 것이라 생각할 수 있다! 초기 컴퓨터는 이런 식으로 프로그래밍됐다.

### The von Neumann Model

ENIAC 같은 reprogramming 방식은 너무 귀찮으니 다른 방법을 찾아보자.

대부분의 현대 컴퓨터가 폰 노이만 구조를 기반으로 한다. Stored program computer architecture.

Datapath와 Control FSM으로 구성되는 **CPU**, **Main Memory**, **Input/Output**으로 구성된다. Input/Output으로 바깥 세상의 기기와 연결할 수 있는데 main memory와 다르게 전원이 꺼져도 데이터가 남아있는 데이터 저장 장치등이 있다.

메모리에 instruction과 data를 모두 저장해보자. CPU는 instruction을 해석하여 요청된 연산을 수행한다. Data를 읽어 register로 옮겨온다. 값만으로는 instruction과 data를 구분할 수 없고 datapath로 로드되면 data, control logic으로 로드되면 instruction이다.

Datapath를 사용해 메인 메모리와 데이터를 주고 받을 수 있다. Control path는 datapath에 control signal들을 제공한다.

Control unit에는 program counter라는 레지스터가 있는데, 여기에 저장된 주소를 사용해 다음 instruction을 메인 메모리에서 가져온다.

Control unit에는 instruction을 해석해 control signal을 만들어내는 로직들이 있다.

> The datapath serves as the brawn of our digital system and is responsible for storing and manipulating data values. The control unit serves as the brain of our system, interpreting the program stored in main memory and generating the necessary sequence of control signals for the datapath.

폰 노이만 구조에서 명령어는 순차적으로(sequentially) 실행된다. 순차적이지 않은 다른 컴퓨터 구조도 있는건가??

Fetch instruction -> Decode instruction -> Read src operands -> Execute -> Write dst operand -> Compute next PC

> The specification of instruction fields and their meaning along with the details of the datapath design are collectively called the **instruction set architecture (ISA)** of the system.

ISA는 하드웨어 설계자와 프로그램 개발자의 접점이다. 프로그램은 메인 메모리에 저장되어 바뀔 수 있기에 바ㄱ뀔 수 없는 디지털 로직과 구분하여 소프트웨어라 부른다.

ISA만 유지한다면 소프트웨어를 바꿀 필요가 없기에 하드웨어의 빠른 개발을 가능하게 하지만, 호환성 때문에 옛날 ISA를 계속 쓰게 되는 문제가 있다. 나쁜 부분을 계속 쓰게 됨.

ISA를 디자인할 때 quantitative approach를 할 수 있다. 여러 벤치마크 프로그램을 선정하고 각각에 대해서 성능을 직접 만든 ISA를 통해 측정한다. 측정의 기준은 여러가지가 있지만 제품의? 맥락에 따라 우선순위를 정한다.

> Identify the common operations and focus on them as you optimize your design.

이제 Beta ISA를 설계해보자.

### Storage

Beta는 RISC(reduced-instruction-set computer) 아키텍처이다. 즉 대부분의 명령어가 oprand와 destination을 위해 내부 레지스터만을 사용한다. 메인 메모리에 접근하려면 별도의 메모리 접근 명령어를 사용해야한다. 작고 고성능의 하드웨어 구현이 가능하고 컴파일러도 간단하다. ARM, MIPS가 RISC이다.

CPU 내부에는 PC와 0-31의 32비트 레지스터가 있다. R31은 0이다.

베타는 word access만 가능하지만 실제 컴퓨터는 바이트와 half-word도 지원한다.

메모리 다이어그램을 그릴 때는 주소가 위에서 아래로 갈수록 커지는 관습이 있다. 그런데 스택은 왜 아래로 자라게 그리지?

레지스터와 메인 메모리를 분리한 이유: Well, modern programs and datasets are very large, so we’ll want to have a large main memory to hold everything. But large memories are slow and usually only support access to one location at a time, so they don’t make good storage for use in each instruction which needs to access several operands and store a result. source와 destination을 명시하는데 32비트가 세 개 필요한건 좀 답이 없음. 적지만 아주 빠른 레지스터를 배치하자. 얘네는 한번에 가져올 수도 있음 굳.

프로그램 데이터들은 메모리에 있다. 변수를 조작하려면 load them -> compute on them -> store the results. 자주 사용되는 값들을 레지스터에 상주시켜 최적화하는 트릭이 자주 사용된다.

> So the basic program template is some loads to bring values into the registers, followed by computation, followed by any necessary stores. ISAs that use this template are usually referred to as **“load-store architectures”**.

RISC와 load-store architecture의 관계는? load-store architecture는 load/store를 위한 명령어가 분리되어있는 것과 상관 있는걸까? 아래 memory access 파트 보면 맞는 것 같고..

### ALU Instructions

- Arithmetic and logical
- Loads and stores
- Branches

모든 명령어의 길이는 같다. Control unit과 다음 PC 로직이 간단해지지만 프로그램 용량이 커진다. 강의 Part 1에서 봤듯이 고정 길이 인코딩은 비효율적이다. 이게 이렇게 이어지네 ㅋ. 요즘엔 메모리 기술이 좋아서 고성능에 집중하기 때문에 고정 길이 명령어도 괜찮다.

opcode(6), rc(5), ra(5), rb(5)

Reg[rc] <- Reg[ra] + Reg[rb] = ADD(ra, rb, rc). 후자는 mnemonic이 사용된 functional notation.

[β Documentation](https://computationstructures.org/notes/pdfs/beta.pdf)

[Summary of β Instruction Formats](https://computationstructures.org/notes/pdfs/betainst.pdf)

### Constant Operands

두번째 피연산자에 상수가 자주 출현하니, 이를 위한 명령어를 추가하는 것이 타당하다. 코드에 한 번 등장해도 루프를 돌다보면 여러번 실행되는 명령어일 수 있다.

rb를 상수로 대체한다. 다만 32비트에 맞아야하니 sign extension을 한다.

명령어에서 rc가 가장 앞에 나오는게 헷갈렸는데, 마지막 위치가 이 경우처럼 레지스터였다가 상수였다가 왔다갔다하는걸 보면 피연산자가 뒤에 나오고 저장할 레지스터가 맨 앞에 나오는게 자연스러운듯. 저장은 무조건 레지스터에 할테니까,,, 맞지?

16비트에 들어가지 않는 상수면 main memory의 특정 위치에 저장해둬야한다.

### Memory Access

Beta가 load-store architecture이기에 이 명령어들이 메모리의 값들에 접근하는 유일한 방법이다.

LD, ST는 ALU-with-constant와 같은 명령어 규격을 가진다.

LD(ra, const, rc) == Reg[rc] <- Mem[Reg[ra] + sext(const)]

ST(rc, const, ra) == Mem[Reg[ra] + sext(const)] <- Reg[rc]

ST 명령어는 유일하게 rc에서 읽는다. Source operand로서 역할해서 symbolic form에서도 첫번째로 등장한다. 또한 register에 쓰지 않는 유일한 명령어다. rc에 const 연산하는게 아니니까 조심!! ST가 반대인 것만 기억하면 rc로 정보가 들어가는게 아니라 나오는거고, 상수 연산은 메모리 주소에만 한다는걸 기억하면 rc 정보를 계산된 주소로 옮기는 것임을 알 수 있다.

나중에 LDR에 대해서도 배울 것임. 지금은 모르겠음,,,

### Branches

지금까지의 설계로는 sequential한 실행밖에 안된다. 프로그램 실행 중 생성한 데이터의 값에 따라 PC를 바꿀 방법(branching)이 필요하다.

특정 조건에 따라 PC를 바꾸는 작업을 **conditional branch**라 한다.

BEQ(ra, offset, rc). branch if Reg[ra] == 0. rc에 NPC(next pc인듯)저장, NPC + 4 \* offset으로 PC 설정.

BEQ/BNE는 offset을 사용한다. 0과 비교해 분기 여부를 파악한다.

> offset: distance in words to branch target, counting from the instructing following the BEQ/BNE. Range: -32768~32767

원래 갔어야 할 PC 주소는 자동으로 rc에 저장된다. 나중에 프로시저 호출등을할 때 유용하다. 필요 없으면 R31 쓰면 됨~

offset이 음수면 backwards branches라 하며 루프의 끝부분에서 주로 사용되고, 양수면 forward branches라 하며 if문에서 스킵할 때 주로 사용된다. R31을 쓰면 무조건 분기도 가능.

BEQ나 BNE에 L: MUL(r0, r1, r0)에서 L 같은 symbolic notation을 서서 루프 내용물이 바뀔 떄마다 바뀐 주소를 다시 집어넣는 귀찮음을 줄일 수 있다. 그러면 symbolic code를 binary instructino fields로 바꾸는 프로그램이 offset calculation을 대신 해준다.

### Jumps

BEQ에서 ra에 R31를 쓴거랑 뭐가 다르지? 무지성 PC 바꾸기라서 편한건가,,, 아무튼 프로시저에서 리턴할 때 유용함.

### Worksheet

1 LD는 상수가 아니라 주소에 접근하는거 잊지 말기

2-B 틀린건 알겠는데 ISA에서 따로 word 단위에 대한 처리는 안해주나?

2-E 어셈블 시간에 표현식은 평가되고 R2라는 symbol을 값으로 평가한다면 2로 된다.

3 .=어쩌구는 주소를 명시하고 LONG(0x어쩌구)는 데이터를 박아 넣는다. 비교 연산자는 무조건 less?

어셈블리어에서의 루프는 while보다는 do-while과 비슷하다.

SHR vs SRA. Arithmetic은 산술적으로, MSB가 복붙된다.

3-H-R1 왜 14????

### Labs

A < B: LSB = N ⊕ V

Another approach that saves gates is to use the left shift logic for both left and right shifts, but for right shifts, reverse the bits of the A operand on the way in and reverse the bits of the output on the way out.

Remember that a good engineer not only knows how to build good designs but also actually builds good designs, and that means testing the design to make sure it does what you say it does.

## 10a Assembly Language

### Intro to Assembly Language

> In the CPU’s control logic there is a special-purpose register called the program counter, which contains the address of the memory location holding the **next instruction** to be executed.

High-level 언어를 사용하여 추상화를 한 단계 끌어올려 레지스터와 ALU 단위에서가 아닌 변수와 수학적 연사의 관점에서 computation을 묘사할 수 있다.

이번 강의에서 어셈블리어에 대해 배우고 다음 강의에서 high-level 언어를 어셈블리어로 어떻게 번역하는지 배워보자.

> A program called the “assembler” reads a text file containing the assembly language program and produces an array of 32-bit words that can be used to initialize main memory.

Symbol은 상수값의 symbolic한 이름이다. Label은 주소를 위한 symbol이다. Macro는 바이트 시퀀스로 확장된다. 대부분 명령어의 축약을 위해 사용된다.

### Symbols and Labels

심벌 이름을 숫자 값으로 연결하는 **symbol table**을 관리한다. 없는거 보이면 테이블에 추가하고, 있는건 테이블에서 찾은 값으로 교체하고.

처음 pass때는 symbol table을 채우고 두번째 pass에서 binary output을 만든다. 이를 통해 forward branch instruction등이 구현 가능하다.

결국에 숫자로 환산되니 상수 자리에 레지스터 쓰거나 그 반대로 써도 어거지로 작동함 주의.

BNE, BEQ에서도 대상 명령어까지의 offset을 알아서 계산해 넣어준다.

### Instruction Macros

```uasm
// Macro to generate 4 consecutive 'bytes'
.macro consec(n) n n+1 n+2 n+3
// Factorial 예시를 보니 연산자 오버로딩이 되는 것 같다.
```

> Little endian: The least-significant byte comes first.

x86도 리틀 엔디안. Beta는 리틀 엔디안을 사용한다.

.align4는 명령어가 word boundary에서 시작하도록 보장한다. Administrative bookkeeping.

어셈블러라는 이름처럼 명령어의 이진 표현이 어셈블되어 각 instruction field를 구성한다.

[UASM?](http://www.terraspace.co.uk/uasm.html). 강의에서 만든 확장자가 아니었나본데?

> We call these macros “pseudo instructions” since they let us provide the programmer with what appears a larger instruction set, although underneath the covers we’ve just using the same small instruction repertoire developed in Lecture 9.

Pseudoinstruction으로 BR할거면 JUMP쓰면 안되나? BR만 상대적이었나,,

### Assembly Language Wrap-up

지금까지는 명령어에 대해서 다뤘는데, 데이터는 어떻게 저장해야될까?

```s
N:     LONG(12)
factN: LONG(0xdeadbeef)
...
LD(N, r1)
```

값은 표현식으로 표현될 수 있고, 평가된 뒤 바이너리에 들어간다.

'.' 심벌은 채워져야할 다음 주소를 나타낸다. 데이터 레이아웃을 조정하거나 배열등을 위해 공백을 남겨둘 때 용이하다. 초기값은 0이고 새 바이트 값이 생길 때마다 증가한다. 사실 k:는 k=.와 같다.

```s
. = 0x100
LONG(0xdeadbeef)
k = . // Symbol k has value 0x104
LONG(0x00dec0de)
. = .+16 // Skip 16 bytes
LONG(0xc0ffeeee)
```

어셈블러는 컴퓨터에서 실행되는 프로그램이다. 닭이 먼저인지 달걀이 먼저인지 문제와 비슷한데, 첫 어셈블러는 바이너리로 손수 어셈블되었을 것이다.

## 10b. Models of Computation

### Models of Computation

어떤 기능들이 ISA에 들어가야할까? NAND가 universal한 것처럼 우리의 ISA가 universal한지 궁금하다. 어떤 computation이든 가능할까? 폰 노이만 구조로 어떤 문제들을 풀 수 있을까?

수학적인 model of computation을 생각해보자.

컴퓨터 과학의 뿌리는 여러 models of computation들이 computation할 수 있는 것들을 찾아가며 자랐다? Universal한걸 찾는 것이 목표였는데 FSM은 universal할까?

FSM은 finiteness하다는 문제점을 지닌다. 괄호 문자열의 균형이 맞는지도 알 수 없음. 임의 개수의 상태가 필요하기 때문에.

이때 앨런 튜링은 무한한 크기의 디지털 테이프에 읽고 쓸 수 있는 FSM의 모델을 제안한다. 튜링 머신(TM).

> So both the input and output of the TM can be thought of as large integers, and the TM itself as implementing an integer function that maps input integers to output integers.

### Computability, Universality

이외에도 정수 입력을 받아 정수 출력을 만드는 함수들의 집합에 관련된 다른 models of computation이 존재한다. Recursive functinos, lambda calculus...

이들은 모두 realizable한 기계에서 풀 수 없는 문제가 있는지 증명하고싶었다.

알고보니 모든 모델들이 같은 집합의 정수 함수를 compute할 수 있었다. 여러 모델간 번역? 작업을 통해 증명됨. 이를 통해 모델에 무관한 computability의 정의가 이루어졌다.

> In computability theory, the Church–Turing thesis is a thesis about the nature of computable functions. It states that a function on the natural numbers can be calculated by an effective method if and only if it is computable by a Turing machine.

f(x) computable <-> for some k, all x f(x) = T_k[x]

튜링 처치 이론은 증명되지 않았다,,,! 신기. 아무튼 일반적으로 computable하다는 것은 어떤 튜링 머신 T를 통해 computable하다는 것이다.

그런데 각 목적별로 ad-hoc스러운 TM을 만들기보다 general-purpose computer를 만들려면 어떻게 해야할까? 특별 목적 기계를 필요로하는 computation이 있을까?

Universal function U를 생각해보자. U(k, j) = T_k[j]이다. U는 computable하고 T_U는 존재한다.

k는 프로그램, j은 입력을 의미한다고 볼 수 있다. T_U는 프로그램을 해석하여 해당 프로그램이 데이터를 처리하는 과정을 에뮬레이트한다.

> KEY IDEA: Interpretation. Manipulate coded representations of computing machines, rather than the machines themselved.

위 아이디어는 stored program computer의 기초를 이룬다.

Universal Turing Machine은 대부분의 현대 컴퓨터의 패러다임이다. 컴퓨터가 Turing Universal임을 보이려면 알려진 UTM을 시뮬레이트할 수 있는지 보면 된다. 메모리가 유한하긴 하지만 이 한계 내에서는 어떠한 computation이든지 할 수 있을 것이다. ISA에 conditional branch와 간단한 산술 연산만 있으면 Turing Universal하다.

> This notion of encoding a program in a way that allows it to be data to some other program is a key idea in computer science. 컴파일, composition, abstraction, language design(separate specification from implementation) 등등...

### Uncomputable Functions

튜링 머신이 할 수 없는 것이 있다. 정지 문제 등등... 유한한 메모리만 제약사항이 아니다. 알고리즘을 아직 모르는게 아니라 알고리즘이 없음을 증명할 수 있다.

정지 문제를 해결할 수 있는 T_H가 있다고 가정하자.

T_N[X] is designed to loop if TM X given input X halts, and vice versa. 즉 T_N[X]는 T_X[X]의 반대로 행동한다. T_H를 통해 구현할 수 있다. k와 j를 같은 곳에 연결한다.

이제 T_N에 N을 입력으로 주면 모순이다. T_H가 T_N[N]이 멈춘다고 했다면 T_N[N]은 루프를 돌 것이다.

### Labs

Constant와 아닌거 구분하기!! SHRC 등등... ST할 때 base 주소 주는 것 잊지 말기, 덧셈 연산 해주는거 잊지 말기. CMP 연산자 잊지 말기.

```s
LD(R2,A-4,R4) // loads A[i-1]
```

## 11. Compilers

### Interpretation & Compilation

고급 프로그램 언어는 storage allocation이나 main memory와의 정보 교환등을 변수와 자료 구조를 활용하여 추상화한다. 어떻게 high-level language를 컴퓨터가 실행할 수 있는 코드로 바꿀 수 있는지 알아보자.

고급 프로그래밍 언어는 특정 ISA의 상세 정보를 추상화시키기 때문에 프로그램이 portable해진다.

고수준 언어를 interpret하기 위해 실제 컴퓨터인 M1에서 돌아가는 인터프리터를 만들어보자.

Model of Interpretation

- 프로그램하기 어려운 M1이라는 기계가 있다.
- M1을 위한 프로그램을 개발한다. 해당 프로그램은 프로그램하기 쉬운 M2의 동작을 mimic한다.
- Virtual M2가 만들어진다.

여러 레이어의 interpretion을 활용할 수 있다. Interpretion은 계산을 한 번만 하거나 어떤 접근법이 우세한지 미리 알아보기 위해 유용하다.

작업을 반복해야해서 장기적으로 더 효율적인 방법이 필요하면 compilation 구현 전략을 사용한다.

Model of Compilation

고수준 프로그래밍 언어 P2를 M1을 위해 번역한다. P2를 실제로 실행하는 것이 아니라 M1에서 실행할 수 있는 P1 프로그램으로 만드는 템플릿으로서 사용된다. 이를 통해 P2를 처리하고 interpretion의 오버헤드를 없앨 수 있다.

아무튼 두가지 방법 모두 프로그램을 실행시킬 컴퓨터의 디테일을 추상화시켜 좋다.

### Compiling Expressions

> A compiler is a program that translates a high-level language program into a functionally equivalent sequence of machine instructions.

우선 고수준 프로그램이 올바른지 체크하고 효과적인 명령어들로 변환한다.

compile_statement와 compile_expr. 전자는 unconditional statement, compound statement, conditional statement, itreration statement. 후자는 constants, variables, assignment, operations, procedure calls.

```
// Constants: 1234 => Rx
CMOVE(1234, Rx)
LD(c1, Rx)
...
c1: LONG(123456)

// Variables: a => Rx
LD(a, Rx)
...
a: LONG(0)

// Variables: b[expr] => Rx
compile_expr(expr) => Rx
MULC(Rx, bsize, Rx)
LD(Rx, b, Rx)
...
b: . = . + bsize*blen

// Assignment: a=expr => Rx
compile_expr(expr) => Rx
ST(Rx, a)

// Operations: expr1 + expr2 => Rx
compile_expr(expr1) => Rx
compile_expr(expr2) => Ry
ADD(Rx, Ry, Rx)
```

> The process we’re following is called “recursive descent”. We’ve used recursive calls to compile_expr to process each level of the expression tree. At each recursive call the expressions get simpler, until we reach a variable or constant, where we can generate the appropriate instruction without descending further. At this point we’ve reached a leaf of the expression tree and we’re done with this branch of the recursion.

> These local transformations are called “peephole optimizations” since we’re only considering just one or two instructions at a time.

### Compiling Statements

```
// Unconditional: expr;
compile_expr(expr)

// Compound: { statement1; statement2; ... }
compile_statement(statement1)
compile_statement(statement2)
...

// Conditional
// if (expr) statement;
    compile_expr(expr) => Rx
    BF(rx, Lendif)
    compile_statement(statement)
Lendif:
// if (expr) statement1; else statement2;
    compile_expr(expr) => Rx
    BF(rx, Lelse)
    compile_statement(statement1)
    BR(Lendif)
Lelse:
    compile_statement(statement2)
Lenfid:

// Iteration
// while (expr) statement;
Lwhile:
    compile_expr(expr) => Rx
    BF(rx, Lendwhile)
    compile_statement(statement)
    BR(Lwhile)
Lendwhile:
// 더 좋은 방법. Iteration당 명령어 하나씩 절약된다.
    BR(Ltest)
Lwhile:
    compile_statement(statement)
Ltest:
    compile_expr(expr) => Rx
    BT(rx, Lwhile)

for (init; test; increment)
    statement;
// 위는 아래와 같다.
init;
while (test) {
    statement;
    increment;
}
```

### Compiler Frontend

Frontend(or analysis)는 statement의 의미(semantics)를 이해하여 코드에 문제가 있다면 보고한다. 기계에 무관한 intermediate representation을 만들어낸다.

Backend(or synthesis)는 IR을 최적화하고 ASM을 만들어내고 ASM를 특정 ISA에 맞게 최적화한다.

Frontend 단계:

Lexical analysis(scanning). 소스 코드를 스캔하여 token 객체들의 시퀀스를 만든다. 에러 보고에 유용하기에 파일 이름이나 줄 수도 기록한다. 유효하지 않은 토큰이 있다면 보고한다.

Syntactic analysis(parsing). 토큰들을 사용해 편리한 자료 구조인 syntax tree를 만든다.

Semantic analysis. Syntax tree를 통해 semantic적으로 올바른지 확인한다. 주로 타입 체킹. Syntax는 맞아도 semantic은 틀릴 수 있다.

이제 syntax, semantic적으로 올바른 syntax tree가 준비되었다. 소스 코드를 동일한 의미의 language-independatnt sequence of operations로 변환하였다. (뭔가 많이 생략된 것 같기는 한데 ㅎ; 아직 트리만 만든거 아님? 아 밑에 보니까 트리가 IR인듯?)

### Optimization & Code Generation

Syntax tree는 소스 코드와 ISA에 모두 무관한 유용한 IR이다. 서로 다른 언어의 frontend가 동일한 backend를 공유할 수 있게 한다. Backend에서의 작업은 IR의 최적화와, ISA로의 번역으로 구성된다.

많은 경우 IR는 control flow graph(CFG)로 syntax tree를 변형한 것이다. 그래프의 각 노드는 branch로 끝나는(optional) 표현식/문의 시퀀스이다. 각 노드는 basic block으로 불린다. 각 블럭은 일단 실행되면 반드시 끝까지 실행된다. 이를 통해 최적화 여지를 찾기 쉽게 한다.

특정 블록 A가 하나의 선행 블록 B를 가진다면, A는 B의 상태를 이어서 사용할 수 있다. 여러개면 겹치는 정보만 사용할 수 있다.

간단한 최적화를 하는 pass를 반복하여 복잡한 최적화를 이룰 수 있다. Dead code elimination, constant propagation(상수인 변수를 상수로 교체), constant folding(상수 표현식을 계산 후 교체).

Common subexpression elimination, loop-invariant code motion, loop unrolling...

타겟 ISA에 맞는 명령어를 만들어보자. 각 변수를 레지스터에 할당한다. 변수가 더 많으면 메모리를 활용한다. 많이 쓰는 변수는 레지스터에 있는 것이 좋다. 이전에 본 템플릿을 활용해서 각 블럭들을 적합한 라벨, 분기를 포함한 명령어로 변환한다. 블럭을 재배치하여 분기를 가능한 줄인다(GCD 예시 보니 처음에는 블럭 사이 이동은 무조건 분기인데 이런 것들 쳐내는 듯). 이후 타겟 ISA에 맞는 peephole optimization을 한다.

Frontend(analysis, 프로그램이 잘 짜여있으면 IR 생성, 아니면 의미있는 에러):

Source code -> (Lexical analysis) -> Tokens -> (Syntactic analysis) -> Syntax tree -> (Semantic analysis) -> Type-checked syntax tree -> IR

Backend(synthesis, 최적화된 프로그램 생성):

IR -> IR(optimized) -> High-quality assembly

## 12. Procedures and Stacks

### Procedures

> Procedure: Reusable code fragment that performs a specific task.

> A procedure call is an expression that has the name of the procedure followed by parenthesized list of values called **“arguments”** that will be matched up with the **formal parameters**.

> Every high-level language comes with a collection of pre-built procedures, called **“libraries”**.

Inline을 통한 구현은 코드의 크기가 늘어나고(크기가 작으면 최적화 과정에서 인라인 할 수는 있다) 재귀를 할 수 없다.

Link to the procedure: 단일한 프로시저 코드를 어딘가 두고 모든 프로시저 호출을 이곳으로 연결한다. 첫번째 명령어가 프로시저의 entry point이다. 호출자는 인수를 평가하고 정해진 위치에 저장하고 프로시저의 entry point로 제어권을 넘긴다. 이후 피호출자는 실행되고 결과를 정해진 위치에 저장하고 호출자에게 제어권을 넘긴다(BR이 return address를 저장한다는 점 활용).

'정해진 위치' -> calling convention이 필요하다. 이 강의에서는 R1에 argument, R28에 return address, 반환값을 R0에. Return address를 저장하는 레지스터를 **linkage pointer**라 부른다.

하지만 재귀 호출 중에 레지스터 값이 덮어쓰기되는 문제가 있다. 각 재귀 호출은 자신의 인자와 리턴 주소를 기억해야한다. 옛날 포트란 같은 경우는 이래서 재귀를 금지했었음,,

> 역량을 발휘할 수 있는 예로는 재귀적 호출을 쓰지 않고 해결할 수 있는 종류가 있다. 포트란은 원래 재귀함수를 지원하지 않았다. 재귀함수를 호출하면 그때마다 필요한 오버헤드를 수행해야 하고, 스택에 있는 변수를 참조할 때 한다리 건너 간접적으로 접근해야 하는 등 속도에 불리한 점이 있다. 포트란의 속도가 빠른 이유가 바로 이것. 90 표준에서는 재귀함수를 지원하지만, 사용에 주의를 요한다. (나무위키)

### Activation Records & Stacks

인자, 반환 주소, 반환값 / 지역 변수, 호출자의 레지스터 값... 들을 저장한 공간이 필요하다.

> So we'll need a block of storage for each active procedure call, what we'll call the "activation record".

재귀 깊이가 얼마나 될지 모르니 정적인 할당은 안되고, 동적 할당을 할 방법이 필요하다.

Note that the activation record of a nested procedure call is always discarded before the activation record of the caller. LIFO. **스택**을 활용하자.

C에서는 현재 실행중인 프로시저의 activation record만 접근해도 좋다. 자바같은건 다른 것도 접근할 수 있다. 자바스크립트처럼 클로저를 지원하거나 파이썬의 yield처럼 continuation을 지원하는 경우 프로시저가 리턴한 후에도 activation record가 남아있어야한다. 이 경우 스택으론 안된다. Allocation과 deallocation을 위한 또다른 scheme이 필요함.

Beta에서의 구현법. R29를 stack pointer로 지정. PUSH에서는 SP를 증가시킨다, 즉 스택은 위로 자란다. (아래로 자라게 하는 구현법도 있다.) SP는 사용되지 않은 첫번째 스택 주소를 가진다.

스택에 PUSH한 코드는 반드시 POP도 해야한다. 이를 stack discipline이라 한다.

많은 아키텍처는 스택 관리를 위한 하드웨어도 있다. 여기서는 software convention만으로 구현한다.

PUSH, POP, ALLOCATE, DEALLOCATE 매크로를 추가하자.

```
REG[SP] <- Reg[SP] + 4;
MEM[Reg[SP]-4] <- Reg[x]
// 순서 바꾸면 덧뺄셈 한번만 해도 될 것 같은데? 아 밑에 설명 있다.
```

> Note that the order of the instructions in the PUSH and POP macro is very important. As we’ll see in the next lecture, **interrupts** can cause the Beta hardware to stop executing the current program between any two instructions, so we have to be careful about the order of operations. So for PUSH, we first allocate the word on the stack, then initialize it. If we did it the other way around and execution was interrupted between the initialization and allocation, code run during the interrupt which uses the stack might unintentionally overwrite the initialized value. But, assuming all code follows stack discipline, allocation followed by initialization is always safe.

### Stack Frame Organization

```
// C code
proc(expr1, ,,,exprn)

// Beta assembly
// We’ll adopt the convention that argument values are pushed in reverse order.
compile_expr(exprn) => Rx
push(rx)
...
compile_expr(expr1) => Rx
PUSH(rx)
BR(proc, LP)
DEALOCATE(n)
```

CALLEE에서는 LP 저장, BP(base pointer, R27) 저장, 필요하다면 local variable 저장. callee saves 컨벤션에 따른다. BP가 없어도 이론상 되지만 offset이 계속 바뀌므로 불편하다.

> We’ll sometimes refer to the activation record as a “stack frame” to remind us of where it lives.

> This is called the “callee saves” convention where the callee guarantees that all register values will be preserved across the procedure call.

인자를 역순으로 푸시하면 첫번째 인자가 고정된 위치에 존재한다. C와 같은 언어에서는 여러 인자를 프로시저에 전달할 수 있는데, 이 개수를 첫번째 인자로 보내려면 이렇게 고정 위치에 있어야한다. printf와 같은 가변 인자 등.

### Compiling a Procedure

Caller:

- PUSH the argument values onto the stack in reverse order.
- Branch to the entry point of the callee, putting the return address into the linkage pointer. When the callee returns, remove the argument values from the stack.

Callee:

- Perform the promised computation, leaving the result in R0. Jump to the return address when the computation has finished.
- Remove any items it has placed on the stack, leaving the stack as it was when the procedure was entered.
- Preserve the values in all registers except R0. So the caller can assume any values placed in registers before a nested call will be there when the nested call returns.

LP와 BP의 저장은 별도로 외우지 말고 호출될 당시 상태를 저장한다는 규약에 맞춰야하기 때문이라고 생각하면 될 듯?

프로시저에서 나갈 때 DEALLOCATE 대신에 MOVE(BP, SP)로 때울 수 있다.

팩토리얼 예시 왜 r1을 여러번 LD하는 것 같지? 이해를 위해 최적화는 뺀건가.

When a problem occurs, many language runtimes will print out the stack trace to help the programmer determine what happened.

### Stack Detective

-

### 기타

[Variable-sized objects on the stack](https://stackoverflow.com/a/36564502)

### Worksheet

4번 문제에서 왜 같은 값을 ST하고 바로 LD하지?

4-D!!!!

### Labs

1-c 마지막 뭘까,,,

JMP는 레지스터의 값을 쓴다.

우로 shift하고 좌로 shift하는 건 그 차이 만큼 좌로 shift하는 것과는 다르다. 1의 자리 정보가 남아있을 수도 있고 아닐 수도 있음.

ST()에서 상수는 가운데!!!!

D?? LP 계산이 어떻게 되는거지

## 13. Building the Beta

### Building Blocks

> An obvious goal is to maximize performance, as measured by the number of instructions executed per second. This is usually expressed in **MIPS**, an acronym for “Millions of Instructions Per Second”.

성능 최대화, 비용 최소화, 가성비 최대화...

> Time / Program = (Instructions / Program) \* (Cycles / Instruction) \* (Time / Cycle)

클럭 당 시간은 propagation delay에 따라 정해진다.

ALU -> Load & Store -> Jump & Branch -> Exceptions 순서로 구현해보자.

Multi-Ported Register File. Load-enabled register들을 사용한다.

> It might seem easier to add enabling logic to the clock signal, but this is almost never a good idea since any glitches in that logic might generate false edges that would cause the register to load a new value at the wrong time. Always remember the mantra: NO GATED CLOCKS!

Register Write 연산도 일반적인 D-레지스터와 같은 요구사항을 가진다. The write address (WA), write data (WD) and write enable (WE) signals must all be valid and stable for some specified setup time and mut remain stable and valid for the specified hold time.

RD1 reads 'old' value of Reg[RA1] until next clock edge???

### ALU Instructions

Fetch -> Decode -> Read -> Execute -> Write-back.

클럭의 상승 엣지는 현재 instruction의 종료이자 다음 insturction의 시작이다.

Fetch/Decode에서는 명령어의 [31:26]비트를 control logic에 넣는다. Control logic은 입력으로 이것만 필요한 듯.

ALUFN control signal은 ALU가 수행할 연산을 알려준다.

WERF는 write-enable register file이다.

BSEL은 constant ALU 연산을 위해 도입되었고 ALU의 B 입력을 Register File의 RD2로 할지 명령어에서 SXT된 C로 할지 선택한다.

### Load and Store

설계도에서는 편의를 위해 instruction memory와 data memory를 따로 그렸지만 사실 하나이다.

메모리에는 MOE(memory output enable)과 MWE(memory write enable) 시그널이 있다.

ADDC의 결과물을 Data Memory의 adr로 연결한다.

WDSEL은 레지스터에 ALU 결과값을 저장할지, 메모리에서 읽은 데이터를 저장할지 결정한다.

ST에서는 RC를 register file read addr에 연결해야한다. 다행히도 Rb는 ST에서 사용되지 않으므로 RA2SEL에서 둘 중 하나를 선택할 수 있도록 한다. ST는 유일하게 결과를 레지스터에 저장하지 않는 명령어이며 WERF가 0이다.

ST에서 MOE가 꼭 0이어야하나? don't care로 두면 안됨? 밑에 JMP에서는 don't care로 두는디...

### Jumps and Branches

Register file의 RD1에서 Reg[Ra]값을 빼와서 PC에 넣는다. 이를 위해 PCSEL control signal이 필요하다.

또한 PC+4값을 Register file에 넣는다. 이전에 만든 WDSEL을 활용한다. Register File의 WA는 항상 Rc에서 와서 편하네.

어셈블러가 해줘도 몰랐는데 BEQ나 BNE도 relative한 브랜칭이었나봄.

RD1으로부터 NOR연산을 해 브랜칭 여부를 판단할 수 있는 Z값을 Control Logic에 넣는다.

LDR는 LD와 다르게 메모리 주소가 branch offset addr로부터 얻어진다. The use case for LDR is accessing large constants that have to be stored in main memory because they are too large to fit into the 16-bit literal field of an instruction.

LD: Reg[Rc] <- Mem[Reg[Ra] + SXT(c)]

LDR: Reg[Rc] <- Mem[PC + 4 + 4 * SXT(c)]

LDR를 위해 ASEL을 추가하고 (PC+4)+4\*SXT(C)를 연결한다. ALU는 A의 값을 그대로 반환한다.

### Exceptions

명령어가 실행될 수 없는 경우를 처리해야한다. 현대 컴퓨터에서 채택된 방법은 실행중인 프로그램을 중지하고 에러 처리 코드로 제어를 넘기는 것이다. 이 테크닉은 I/O와 관련된 외부 이벤트에도 활용된다.

> This is a very powerful feature since it allows us to transfer control to software to handle most any circumstance beyond the capability of our modest hardware.

> Exceptions usually refer to synchronous events, generated by program (e.g., illegal instruction, divide-by-0, illegal address)

> Interrupts usually refer to asynchronous events, generated by I/O devices (e.g., keystroke, packet received, disk transfer complete)

따라서 프로그램이 같은 데이터로 재실행되면 같은 exception이 발생한다. Interrupt는 실행되는 프로그램의 상태와 무관한 시간에 발생한다.

예외가 발생하면 XP(exception pointer)에 PC+4를 저장하고 PC를 특정 위치로 이동시킨다. 해당 위치에서 적합한 handler routine을 실행한다.

XP의 값은 언제 덮어씌워질지 모르므로 유저 프로그램을 사용할 수 없다.

XP로의 저장을 위해 WASEL을 추가한다. write-back을 XP에 하도록 한다. PCSEL MUX에 exception handler들을 추가한다.

interrupted instruction은 실행되지 않았으므로 저장된 XP 값에서 4를 빼야할 수도 있다.

### Summary

IRQ는 어디서 쓰이는거야? Interrupt request...

MWR는 항상 명시된 값을 가진다. WERF도 RESET을 제외하고 명시된 값을 가진다.

### Worksheet

ASEL의 1은 상대 주소 계산을 위해서.

BSEL의 1은 상수 계산을 위해서

MOE는 MWR이 1일 때는 0이어야함. 수업에서 가정하는 memory의 특성때문에 그런듯? 동시 R/W가 안되나 봄.

MWR는 ST 제외 0.

PCSEL은 상대 분기, 점프, 예외처리. 리셋용 MUX는 따로 있네~?

RA2SEL가 1일때는 ST에서 꼼수?용.

WASEL의 1은 예외 처리.

WDSEL은 레지스터에 저장할 것 판단용. WERF는 레지스터 저장 유무 설정.

거의 모든 명령어는 레지스터에 저장하여 마무리된다!!

### Labs

R31의 0에 대한 처리는 read 혹은 write 둘 중 하나에만 해줘도 된다. read를 0으로 예외처리하면 저장시켜도 상관 없음.

beta/regfile 테스트 40이 이상한디?? 39에서 잘 저장하는거 맞나,, -> 이거때매 뒤에서 개고생함,, 테스트 파일이 맞다,,

OP[5:0]와 ALUFN[5:0]이 다른거 이해하기.

MWR needs to be forced to 0 when RESET is 1. Note that this takes precedence over any values determined by IRQ ?? any values라는게 뭘 말하는거지.

ctl만들 때 왜 기본값이 0b??????_??_?0*011*?\_1001 인지 모르겠음!

아래처럼 묶어서 생각하는 아이디어

```
// alufn[5:0]
// asel, bsel
// moe, mwr
// pcsel[2:0]
// ra2sel
// wasel, wdsel[1:0], werf
```

> The high-order bit of the register, PC[31], is used as the supervisor bit. When the supervisor bit is 0, the Beta is in user mode, executing programs normally with interrupts enabled. When the supervisor bit is 1, the Beta is in supervisor mode (sometimes called kernel mode), executing kernel code with interrupts disabled.

> We're ignoring the low-order 2 bits of the register value and instead should use 0b00 as the correct value for these bits since instructions are always on a word boundary.

베타 컴포넌트와 메모리 컴포넌트로 나뉘는 개념 이해하기.

> When connecting the PC_OFFSET output from the PC module to the "1" input of the ASEL mux, you should ignore the high-order bit and use 0'1 instead, since we don't want to use the supervisor bit as part of the LDR address.

## 14. The Memory Hierarchy

### Memory Technologies

> The performance of most modern computers is limited by the bandwidth, i.e., bytes/second, of the connection between the CPU and main memory, the so-called memory bottleneck.

이 병목을 이해하고 줄여보자.

SRAM(static), DRAM(Dynamic).

용량이 커지면 capacitive loads가 커져 느려진다.

평균적인 성능을 높이는게 목표다. 통계적인 성질을 살펴보게 될 것. Worst case가 존재한다. (알고리즘이랑 비슷한 듯?)

### SRAM

> The address decoder logic sets one of the 8 wordlines (the horizontal wires in the array) high to enable a particular row (location) for the upcoming access.

> During read operations the bit lines carry the analog signals from the enabled bit cells to the sense amplifiers, which convert the analog signals to digital data.

> SRAM Cell: Two CMOS inverters (4 MOSFETs) forming a bistable element. + Two access transistors.

Read:

1. Drivers precharge all bitlines to Vdd, and leave them floating
2. Address decoder activates one wordline.
3. Each cell in the activated word slowly pulls down one of the bitlines to GND.
4. Sense amplifiers sense change in bitline voltages, producing output data.

Write:

1. Drivers set and hold bitlines to desired values.
2. Address decoder activates one wordline.
3. Each cell in word is overpowered by the drivers, stores value.

> Read and writes are essentially analog operations performed via the bitlines and access FETs.

### DRAM

> We can use a simple capacitor for storage, where the value of a stored bit is represented by voltage across the plates of the capacitor. The resulting circuit is termed a dynamic random-access memory (DRAM) cell.

SRAM cell보다 20배정도 작아서 더 밀도있고 싼 메모리를 만들 수 있지만 capacitor의 charge가 빠져나가기에 주기적(약 10ms, refresh cycle)으로 refresh해줘야한다.

> here are some challenges however. There’s no circuitry to main the static charge on the capacitor, so stored charge will leak from the outer plate of the capacitor, hence the name dynamic memory.

Write:

Drive bitline to Vdd or GND, activate wordline, charge or discharge capacitor.

Read:

1. Precharge bitline to Vdd/2.
2. Activate wordline.
3. Capacitor and bitline share charge.
4. Sense bitline to determine if 0 or 1.
   - Reads are destructive! So, data must be rewritten to cell at end of read.

> DRAM circuitry is usually organized to have wide rows, i.e., multiple consecutive locations are read in a single access. This particular block of locations is selected by the DRAM row address.

따라서 한번 row를 읽으면 그 이후 같은 row의 다른 column의 데이터는 빠르게 접근이 가능하다.

> In summary, DRAM bit cells consist of a single access FET connected to a storage capacitor that’s cleverly constructed to take up as little area as possible. DRAMs must rewrite the contents of bit cells after they are read and every cell must be read and written periodically to ensure that the stored charge is refreshed before it’s corrupted by leakage currents.

> DRAMs have much higher capacities than SRAMs because of the small size of the DRAM bit cells, but the complexity of the DRAM interface circuitry means that the initial access to a row of locations is quite a bit slower than an SRAM access. However subsequent accesses to the same row happen at speeds close to that of SRAM accesses.

### Non-volatile Storage; Hierarchical Memories

**Flash**

> In flash memories, long-term storage is achieved by storing charge on an well-insulated conductor called a floating gate, where it will remain stable for years.

> By setting the gate terminal to a voltage between V_1 and V_2, we can determine if the floating gate is charged by testing to see if the MOSFET is conducting.

> Read access times for **NOR flash memories** are similar to that of DRAMs, several tens of nanoseconds. Read times for **NAND flash memories** are much longer, on the order of 10 microseconds.

> Write times for all types of flash memories are quite long since high voltages have to be used to force electrons to cross the insulating barrier surrounding the floating gate.

> Flash memories can only be written some number of times before the insulating layer is damaged to the point that the floating gate will no longer reliably store charge.

이 횟수 제안을 넘기 위해 플래시 칩에는 address mapping algorithm를 통해 같은 주소에 대한 읽기가 다른 플래시 셀에서 이루어진다(?)

> The bottom line is that flash memories are a higher-performance but higher-cost replacement for the hard-disk drive, the long-time technology of choice for non-volatile storage.

**Hard Disk**

> The average total time required to correctly position the head is on the order of 10 milliseconds, so hard disk access times are quite long.

> However, once the read/write head is in the correct position, data can be transferred at the respectable rate of 100 megabytes/second.

> Hard disk drives provide cost-effective non-volatile storage for terabytes of data, albeit at the cost of slow access times.

```
            Capacity    Latency     Cost/GB
Resigter    1000비트     20ps        $$$
SRAM        10KB-10MB   1-10ns      ~$1000
DRAM        ~10GB       80ns        ~$10
Flash       ~100GB      100us       ~$1
Hard disk   ~1TB        10ms        ~$0.1
```

> Interestingly, although capacities and transfer rates for DRAMs and HDDs have improved, their initial access times have not improved nearly as rapidly. Thankfully over the past decade flash memories have helped to fill the performance gap between processor speeds and HDDs. But the gap between processor cycle times and DRAM access times has continued to widen, increasing the challenge of designing low-latency high-capacity memory systems.

> The capacity of the available memory technologies varies over 10 orders of magnitude, and the variation in latencies varies over 8 orders of magnitude.

어떻게 크고 빠른 메모리를 얻을 수 있을까? 메모리들의 위계 시스템을 만들어서 용량이 크고, 빠르고, 값싼 메모리를 에뮬레이트해보자!

첫번째 방법은 어떤 종류의 메모리에 접근할 수 있는지 개발자들에게 맡기는 것. 슈퍼컴퓨터의 권위자인 Seymour Cray가 옹호했다.

두번째 방법은 위계를 숨기고 개발자에게는 하나의 큰 주소 공간만을 보이게하는 것. 실제로는 데이터의 사용 패턴에 따라 메모리 위계를 오간다. CPU가 요청한 주소를 보고 어디에 있는지 찾는 회로가 필요하다.

> Could the memory system automatically arrange for the right data to be in the right place at the right time? Cray was deeply skeptical of this approach. He famously quipped “that you can’t fake what you haven’t got”. Wouldn’t the programmer, with her knowledge of how data was going to be used by a particular program, be able to do a better job by explicitly managing the memory hierarchy?

그래도 general-purpose programs를 실행할 떄는 이러한 memory system을 만들 수 있다.

### The Locality Principle

> Access to address X at time t implies that access to address X+ΔX at time t+Δt becomes more probable as ΔX and Δt approach zero.

SRAM에 자주 사용되는 데이터를 넣는다. SRAM은 보통 CPU칩 내부에 존재한다. DRAM은 main memory의 역할을 하며 최대한 가끔 접근한다.

메모리 위계간 데이터의 이동이 amortize되어야한다.

Instuction fetches는 대부분 부근에서 이루어지기에 DRAM의 빠른 column 접근을 활용할 수 있다. 첫 접근의 비용은 이후 접근들로 amortize된다.

> Some programming constructs, e.g., method dispatch in object-oriented languages, can produce scattered references to very short code sequences but order is quickly restored.

> Once the time interval reaches a certain size the number of locations accessed is approximately the same independent of when in time the interval occurs.

따라서 SRAM은 working set을 담을 정도로 크면 된다.

> Cache: A small, interim storage component that transparently retains(caches) data from recently accessed locations.

캐시에 요청한 데이터가 있으면 cache hit, 없으면 cache miss.

캐시의 개념은 하드웨어를 넘어서 웹 캐시 등 넓게 활용된다.

> There are three levels of on-chip SRAM caches, followed by DRAM main memory and a flash-memory cache for the hard disk drive.

레지스터에 있을 값은 컴파일러가 결정한다. 칩 내부에 있는 세 레벨의 SRAM 캐시는 메모리 시스템에 있는 회로가 관리한다. 그보다 아래는 소프트웨어/OS가 관리한다. 이번엔 칩 내부에 있는 캐시들에 대해 배우고 위에서 어떻게 소프트웨어가 메인 메모리와 비휘발성 메모리를 관리하는지 알아보자.

### Caches

생각해보니까 지난 강의까지는 메모리가 한 사이클 내에 값을 돌려준다고 가정하고있었네. 사실은 프로세서가 hit/miss 여부에 따른 가변적인 메모리 접근 시간을 처리해야함을 알자!

> The processor has to deal with the variable memory access time, perhaps by simply waiting for the access to complete, or, in modern hyper-threaded processors, it might execute an instruction or two from another programming thread.

HR(Hit Ratio), MR(Miss Ratio), HT(HitTime), MP(Miss Penalty).

HR = 1 - MR, MR = 1 - HR.

> Average Memory Access Time(AMAT): HT\*HR + MR\*MP = HT(1-MR) + (HT+MP)\*MR = HT + MP\*MR

여러 레벨의 캐시가 있으면 위 공식을 재귀적으로 적용할 수 있다. 레벨이 낮아질수록 느려지고, 용량이 커지므로 MR은 작아진다.

> AMAT = HT_L1 + MR_L1 \* AMAT_L2

모든 캐시 접근은 일단 hit time이라고도 불리는 캐시 접근 시간이 필요하다.

> A combination of a data block and its associated address tag is called a cache line.

HIT/READ면 읽으면 되고, HIT/WRITE면 캐시의 데이터를 바꾸고 메모리에 쓰기를 시작한다(다른 방법도 있었던 것 같은데?).

MISS면 일단 정보를 담을 cache line을 선택한다. 이후 READ, WRITE는 비슷.

이제 캐시의 내용물을 빠르게 탐색할 방법을 찾아보자. 특정 address tag의 유무를 빠르게 알 수 있어야한다.

### Direct-Mapped Caches

모든 메모리 word는 각각 하나의 cache line에 대응된다. 이름도 여기서 유래.

캐시에 2^W개의 line이 있으면 메모리 주소는 Tag bits, Index bits(W), Offset bits(2)로 나뉜다.

캐시는 Valid bit, Tag, Data(32 bit)로 구성된다.

캐시가 valid한지, tag비트가 같은지 비교하여 같으면 그 값을 가져온다.

> The CPU can request that the valid bit be cleared for a particular cache line — this is called flushing the cache.

> Part of the address(index bit) is encoded in the location! Tag + Index bits unambiguously identify the data's address.

Example에서 line 2는 태그값이 달라서가 아니라 Valid bit가 0이라서 아닌게 더 정답 아닌가?!

### Block-size; Cache Conflicts

DM 캐시에서 data의 크기를 2, 4 words로 늘린다.

> The number of data words in each cache line is called the block size and is always a power of two.

블럭 크기가 늘어날수록 valid bit와 tag로 인한 오버헤드가 줄어들고 SRAM을 더욱 효과적으로 사용하게 된다. Locality를 더 활용할 수 있다.

4-block, 16-word DM cache에서는 주소를 tag bits(26), index bits(2), block offset bits(4)로 나눈다. block offset bits의 상위 2비트로 블럭들중 무엇을 반환할지 선택한다.

> With a larger block size we have to fetch more words on a cache miss and the miss penalty grows linearly with increasing block size. Note that since the access time for the first word from DRAM is quite high, the increased miss penalty isn’t as painful as it might be.

총 캐시 용량이 그대로라고 가정하면 블럭 크기를 늘리면 캐시 라인 개수가 줄어든다. Working set을 감당할만큼의 별개의 주소 블럭이 있을정도로는 캐시 라인 개수가 있어야한다. 따라서 블럭 크기 대비 MR의 그래프는 U자형?이다.

현대 프로세서에서 블럭 사이즈는 주로 16 word이다.

하지만 DM 캐시는 데이터 주소와 명령어 주소가 충돌할 수 있다는 단점이 있다. Conflict miss. 즉, 각 주소는 정확히 하나의 위치에만 존재할 수 있다. Inflexible mapping.

### Associative Caches

> Associative: of or denoting computer storage in which items are identified by content rather than by address.

> A fully-associative (FA) cache has a tag comparator for each cache line.

어떤 주소든 아무 위치에 있을 수 있다. Cache index가 존재하지 않는다. 유연하지만 모든 태그를 비교해야하기에 구현하기 비싸다.

이건 너무 극단적이니 DM과 FA 사이 N-way Set-Associative Cache가 나왔다. 사실상 N개의 DM 캐시가 병렬로 작동하는 것이다.

Rows = Sets, Columns = Ways, Set size = # Ways, 4-way = 4 entries/set.

같은 cache index를 N개까지 감당할 수 있다.

특정 way를 선택할 때 address bit를 사용하지 않기에 굳이 2의 지수 개수일 필요 없다.

몇 개의 way가 필요할까? 지역의 개수를 세보면 code, stack, data 정도고 복사 붙여넣기 등의 연산을 포함한다쳐도 그렇게 많은 양의 way가 필요하지는 않다. Way가 많아질수록 conflict miss는 줄지만 hit time은 늘어나니 적당히 골라야한다. 8-way가 적당.

Cache miss가 발생했을 때 N개의 cache line중에 어디에 저장해야할까? 미래의 hit ratio에 미치는 영향을 최소화할 수 있는 cache line을 선택해야한다.

Least-recently-used replacement strategy, LRU. 매번 업데이트하는 것도 일이라서 대부분 근사를 활용함.

랜덤을 제외한 모든 replacement strategy는 defeat할 수 있다. HR가 엉망인 프로그램을 임의로 만들 수 있다.

### Write Strategies

Write 요청이 왔을 때 메인 메모리는 어떻게 갱신할까?

Write-through: 즉시 메인 메모리에도 쓰고 그동안 CPU는 stall. Simple, slow, wastes bandwidth. 연속된 쓰기 작업이 있으면 메인 메모리에는 마지막 쓰기만 적용해도 되니 낭비다.

Write-behind: 쓰기 작업을 버퍼에 넣고 메인 메모리에 쓰는 동안 CPU는 실행 가능. Faster, wastes bandwidth. 쓰기 대기중인데 cache miss가 나면 쓰기가 완료되기까지 기다려야된다.

Write-back: 블럭이 교체될 때까지 미룸. 메모리 내용이 stale할 수 있음. Fastest, low bandwidth, complex. 현대 시스템에서 많이 씀.

블럭마다 dirty bit를 추가해 변경이 있는지 기록한다.

### Summary

Larger block size: Trade off spatial? for temporal locality, higher miss penalty.

> Increasing the block size of the cache let us take advantage of the fast column accesses in a DRAM to efficiently load a whole block of data on a cache miss. The expectation was that this would improve AMAT by increasing the number of hits in the future as accesses were made to nearby locations.

### Worksheet

비트는 log배로, 개수는 지수배로 바뀐다.

SA 캐시에서 어떤 set?에 있는지는 따로 mux가 있는게 아니라 같은 cache index를 가지는 row들끼리 태그 비교 연산을 한다. 특정 못하는게 자연스러움, 특정하면 DM이지 뭐..

> the cache is empty, i.e., all the V bits have been set to 0.

### Lab

> The sequence of addresses is sometimes called the reference string.

> The instructions in the inner loop are all executed once for each data access, so the cache lines holding these instructions will never be "least recently used" when a cache line needs to be replaced due to a data miss.

> There's no notion of a partially-filled cache line.

> Sequential array accesses are good examples of the principal of locality. An increased words/line will bring in neighboring array elements on a miss and those neighbors will be accessed in successive iterations. So at a slightly larger refill cost (bringing in the extra words), there's a big impact on the miss rate.

> Most modern CPUs use separate caches for instruction fetch and data accesses as the first level of their memory hierarchy. That way misses from data accesses will never interfere with cached instructions, potentially increasing the hit rate of the instruction cache. Instruction caches can be simpler since they don't have to deal with write requests and so don't need the machinery associated with dirty bits, write back, etc.

equal24 구현 둘러보기. Inverting 게이트들을 활용한 최적화. AND/OR 왔다갔다하는 것 같지만 결국에는 OR임.

reset이 1이면 hit도 miss도 아니게 되는 듯.

이제 1 cycle 1 instruction이 아닌데 CPU에서는 이걸 어떻게 처리할까? 예전에 배운 handshake protocol 이런건가,,

irdy가 아니면 id의 값은 신경쓰지 않는 듯.

The LRU state needs to be updated at the end of every request, i.e., whenever irdy is 1.

LRU 값은 가장 안쓰인 way! Cache line을 읽고 쓸 때 모두 업데이트해야한다. hit과 cwe의 OR로 가능.

FSM은 특정 회로의 값이 이 시점에 유효함을 알려주는 느낌.

원래는 리셋하면 캐시 내용물도 날려야되는건가?

## 15. Pipelining the Beta

### Improving Beta Performance

> For memory operations, the output of the ALU serves as the memory address and, in the case of load instructions, the main memory supplies the data to be written into the register file at the end of the cycle. PC+4 and ALU values can also be written to the register file.

> We’re forced to choose the clock period to accommodate the worst-case execution time, even though we may be able to execute some instructions faster since their execution path through the circuitry is shorter.

간단한 명령어는 한 클럭 사이클에, 복잡한 것은 여러 사이클에 돌 수 있게 해보자?? 내 기억에는 다 다섯사이클이었는데 함 보자,,

Instruction Fetch stage(IF) -> Register File stage(RF) -> ALU stage(ALU) -> Memory stage(MEM) -> WB(Write-Back stage)

명령어가 여러 사이클에 걸쳐서 실행되지만 결과적으로 throughput은 1 per clock cycle이다.

레지스터와 메모리에 상태 정보가 있어서 무지선 파이프라이닝으로는 안된다. 이후 파이프라인 단계가 이전 단계에 영향을 미치는 경우가 있다. Execution dependencies between instructions.

Pipeline Hazards. 데이터 관련이면 data hazard, PC 관련이면 control hazard.

### Basic 5-stage Pipeline

다음 PC는 무조건 PC+4, 읽기 전용 레지스터와 쓰기 전용 레지스터가 있는 datapath로 일단 시작해보자.

> Note that data accesses to main memory span almost two clock cycles. Data accesses are initiated at the beginning of the MEM stage and returning data is only needed just before the end of the WB stage. The memory is itself pipelined and can simultaneously finish the access from an earlier instruction while starting an access for the next instruction.

> Note that the effects of the green LD, i.e., filling R2 with a new value, don’t happen until the rising edge of the clock at the end of cycle 5. In other words, the results of the green LD aren’t available to other instructions until cycle 6.

레지스터 읽기는 RF 단계에서, 쓰기는 WB 단계 마지막에 일어난다.

### Data Hazards

Read-after-write dependency. 쓰기 이후에 읽기가 있으면 파이프라인에서 문제가 발생한다.

Stall.

CPI를 증가시킨다. 빈 단계에 NOP(no operation)을 삽입하며 이를 버블이라고도 한다.

RF 단계에서의 RA와 RB를 ALU/MEM/WB 단계에 있는 RC와 비교해서 stall 여부를 판단할 수 있다.

Stall되면 PC 정지, RF 단계의 입력 레지스터 정지, ALU 단계에 NOP 전달이 이루어진다.

Bypass(aka Forward).

필요한 값이 파이프라인 어딘가에 있을 때 활용할 수 있다. 값이 계산되는대로 앞쪽 파이프라인 단계로 값을 보낸다.

ALU, MEM, WB의 destination 레지스터가 RF의 source 레지스터와 같다면 이들을 사용한다. 물론 R31은 예외. 여러개가 겹치면 가장 최근값!

분기나 점프는 PC+4를 레지스터에 쓰기에 완전한 bypass는 이들도 포함한다. 하지만 그만큼 회로가 복잡해지고 크기가 커져서 적당히만 bypass시켜도 좋다.

ALU값을 계산하는데 시간이 걸리는 것처럼 bypass는 사이클 마지막에 이루어지기에 클럭 시간을 늘려야한다.

Fully bypass를 하더라도 LD와 같이 결과가 ALU 단계 이후에 발생하면 WB의 마지막까지 기다려야되므로 stall logic은 필요하다. Bypass로 다룰 수 없는 유일한 data hazard. load-to-use hazard라 불린다.

파이프라인 단계가 많아질수록 data hazard가 빈번해지니 t_CK는 줄여도 CPI는 커진다.

컴파일러는 의존적인 명령어들을 떨어트려놔 stall을 줄일 수 있다.

> The bottom line is that successful ISAs have very long lifetimes and so shouldn’t include tradeoffs driven by short-term implementation considerations. Best not to go there.

### Control Hazards

다음 PC값을 알려면 일반적으로 Opcode(Halt 때문?)과 PC+4를 알면 되지만, BEQ/BNE나 JMP의 경우 Reg[Ra]도 알아야한다.

레지스터값을 알아야해서 control hazard가 발생한다.

> In the case of JMPs and taken branches, we don’t know what the IF stage should be doing until those instructions are able to access the value of the RA register in the RF stage.

**Stall**

한 사이클 비운다. Bypass해도 한 칸 비워야되는거 참고.

> If we replace an instruction with NOP, we say we “annulled” the instruction.

> If we annul instructions in all the earlier pipeline stages, this is called “flushing the pipeline”. Since flushing the pipeline has a big impact on the effective CPI, we do it when it’s the only way to ensure the correct behavior of the execution pipeline.

**Speculate**

값을 예측하고 실행.

CPU 상태에 영향(side effect)을 미치는 단계가 뒷쪽에 있기 때문에 IF/RF/ALU에서 실행시키다가 annulled해도 좋다.

> We’ll be using the same data path circuitry as before, we’ll just be a bit more clever about when the value of the IRSrc_IF control signal is set to 1. Instead of setting it to 1 for all branches, we only set it to 1 when the branch is taken.

파이프라인이 깊어질수록 잘못된 branch prediction은 큰 낭비를 만든다. 따라서 현대 프로세서는 복잡한 speculation 매커니즘을 사용한다. 분기의 역사를 살펴보고 높은 확률의 것을 선택한다. 예를 들어 브랜치 인덱스가 음수면 루프라고 간주할 수 있음.

swift에서 별도의 guard문이 있을 때 if문이랑 다르게 컴파일, branch prediction을 할 수도 있을까?

ISA를 바꿔 점프나 분기 이후 명령어가 반드시 실행되도록 할 수도 있다. 이때 이후 명령어를 **branch delay slot**이라 한다.

컴파일러가 슬롯을 잘 활용하면 좋지만 어렵다. 파이프라인이 길어지면 슬롯도 많아져야하고 분기 예측이 실용적이다. ISA를 바꾸는건 나쁘다!!

> ISAs outlive implementations, so it’s best not to change the execution semantics to deal with performance issues created by a particular implementation.

### Exceptions and Interrupts

Exception은 결과적으로 분기이기때문에 control hazard를 유발할 수 있다.

Precise exception?을 위해 exception 이전 명령어는 실행이 완료되어야하고 exception을 유발하는 명령어와 그 이후 명령어는 실행되면 안된다.

WB 전에는 side effect가 없기때문에 날려도 좋다. WB에서는 exception의 우려가 없나보지?

특정 단계에서 exception이 발생하면 해당 명령어를 BNE(R31, 0, XP)로 바꾸어 PC+4를 저장하고 이 이전 단계들은 flush the pipeline한다. 그리고 PC를 IllOp나 XAdr로 바꾼다.

한 사이클에서 여러 명령어의 exception이 감지되면 파이프라인 깊숙히? 있는 명령어를 우선한다.

Extenal interrupt는 IF에서 exception이 발생한 것처럼 처리한다. BNE(..., XP)를 IF에 넣고, Xadr를 다음 PC로 설정한다. 이때 code handler에서는 XP-4로 복귀해야하는 것 주의.

### Lab

작업에 필요한 값은 RF에서 가져온다. 따라서 bypass의 목적지는 RF이다.

IRSrc_IF는 branch prediction 틀렸을 때, IRSrc_RF는 LD 기다릴 때(피연산자 레지스터가 data path에 없을 때). IRSrc_RF가 1이면 stall도 1이다.

무조건 분기라고 따로 처리는 안하는 듯?? BR인데 branch prediction에 포함됨.

Predication. All the compare instructions write their result into a special 1-bit register, called the predicate register.

## 16. Virtual Memory

### Even More Memory Hierarchy

챕터 14에서는 CPU와 메인 메모리 사이에있는 하드웨어 서브시스템인 캐시에 대해서 배움. Level 1-3 Cache가 있다.

> In order to increase the probability that requested addresses reside in the cache, we introduced the notion of “associativity”, which increased the number of cache locations checked on each access and solved the problem of having, say, instructions and data compete for the same cache locations.

오늘은 메인 메모리로 데이터를 어떻게 옮기는지 살펴보자. 일단은 캐시가 없다고 가정.

플래시 드라이브나 하드디스크같은 비휘발성 저장매체는 secondary storage라 한다. 메인 메모리는 primary storage.

캐시는 하드웨어로 관리했지만 가상 메모리는 소프트웨어/운영체제로 관리한다.

가상 메모리 시스템을 통해 프로그램이 접근할 수 있는 데이터를 제한하고 하나의 CPU에서 여러 프로그램을 실행시키는 초석을 다지게 된다.

캐시와 메인메모리에 비해 메인 메모리와 secondary storage 사이의 access latency 차이와 sequential access의 유익이 훨씬 크다.

> Design decisions driven by enormous cost of misses.

Miss penalty가 상당히 크기 때문에 소프트웨어에서 처리해도 좋다. Hit은 하드웨어에서, miss는 소프트웨어에서 처리해보자.

### Basics of Virtual Memory

> The memory addresses generated by the CPU are called **virtual addresses** to distinguish them from the physical addresses used by main memory.

> In between the CPU and main memory there’s a new piece of hardware called the **memory management unit (MMU)**. The MMU’s job is to translate virtual addresses to physical addresses.

> The MMU hardware translates virtual addresses to physical addresses using a simple table lookup. This table is called the **page map** or **page table**.

요청한 주소가 없으면 CPU에 memory-management exception을 보내면 해당 주소에 물리 메모리를 할당하고 필요한 I/O 작업을 한다.

MMU table을 갈아끼워 여러 프로그램을 동시에 실행할 수 있고 프로그램 전체를 로드하지 않고 필요할때 가져올 수 있다. 프로그램의 현재 working set만 메인 메모리에 있으면 됨!

> MMU plays a central role in the design of a modern timesharing computer system.

가상/물리 주소를 page라 하는 고정된 크기(2^p)로 나눈다. 4KB~16KB. 주소의 low-order p 비트들을 page offset으로 사용한다. 남은 비트들은 page number라 한다.

MMU가 VPN(virtual page number)을 받으면 이를 PPN으로 변환하고 뒤에 page offset을 붙여 메인 메모리에 접근한다.

요청된 가상 페이지가 메인 메모리에 없으면 MMU는 memory-management exception을 일으킨다. **Page fault**라 한다.

> Using main memory as page cache = _paging or demand paging_

CPU는 어떻게 virtual address로 요청하지?? 아무튼 요청한 virtual memory가 MMU에 없으면 page fault exception을 날리고, CPU가 page fault handler를 실행하고, 특정 physical page가 viretual page를 담당?하게 하고, 이차 저장장치에서 로드해온다. 이후 page map을 업데이트한다.

> It is possible to write programs that constantly generate page faults, a phenomenon called thrashing.

> The offset into the physical page is always the same as the offset into the virtual page.

### Page Faults

> Are there any restrictions on which page we can select? Obviously, we can’t select the page that holds the code for the page fault handler. Pages immune from selection are called **“wired” pages**.

[Page replacemenet algorithm](https://en.wikipedia.org/wiki/Page_replacement_algorithm). Aging 알고리즘이 꽤 쓰임.

Physical page는 메인 메모리(physical memory)에 있는걸 의미하는듯.

```c
// DiskAdr array holds the location in secondary storage for each virtual page.
// DiskAdr 값은 어떻게 아는데??? 이럼 결국 physical address가 노출되는거 아닌가?
// Page table pointer가 이 역할을 하는걸까

int VtoP(int Vaddr) {
    int VPageNo = Vaddr >> p;
    int P0 = Vaddr & ((1 << p) - 1);
    if (R[VPageNo] == 0)
        PageFault(VPageNo);
    return (PPN[VPageNo] << 0) | P0;
}

void PageFault(int VPageNo) {
    int i;

    i = SelectLRUPage();
    if (D[i] == 1)
        WritePage(DiskAdr[i], PPN[i]);
    R[i] = 0;

    PPN[VPageNo] = PPN[i];
    ReadPage(DiskAdr[VPageNo], PPN[i]);
    R[VPageNo] = 1;
    D[VPageNo] = 0;
}
```

VtoP는 자주 사용되고 성능이 중요하니 하드웨어로, PageFault는 드물고 예외적이니 소프트웨어로 구현하자.

### Building the MMU

> Since CPU implementations are expected to change every couple of years, the choice of physical memory size can be adjusted to match current technologies. Since programmers use virtual addresses, they’re insulated from this implementation choice.

Page map을 위해서 별도의 RAM을 쓰기에는 비싸다. 메인 메모리의 일부를 활용해보자.

> We could use a register, called the **page map pointer**, to hold the address of the page map array in main memory.

즉, page map은 별도의 physical page를 할당받아 사용하게 된다. 별도의 하드웨어가 필요없지만 하나의 virtual access의 두 번의 physical memory 접근이 필요하다.

> Most systems incorporate a special-purpose cache, called a **translation look-aside buffer (TLB)**, that maps virtual page numbers to physical page numbers.

> When we change the R bit to 0 in the page map, we have to do the same in the TLB.

### Contexts

> A **context** is a mapping of VIRTUAL to PHYSICAL locations, as dictated by contents of the page map.

프로그램마다 별개의 context를 가지게하여 서로 간섭하지 못하게 할 수 있다.

> The OS is effectively creating many virtual machines and choreographing their execution using a single set of shared physical resources.

> The OS runs in a special OS context, which we call the kernel.

kernel mode / user mode. Kernel 모드에서는 MMU state, I/O 기기 등등에 접근할 수 있다. 따라서 user mode에서 이들을 접근해야한다면 커널에 대신 요청한다. 이 관련 내용은 다음 시간에~

프로그램의 가상 주소는 접근 불가능한 영역(초기화 안된 포인터 등의 에러를 잡기 위해), 프로그램과 프로그램이 사용하는 라이브러리의 코드가 포함된 읽기 정용 구역, procedure activation record를 담는 스택과 동적으로 사용되는 공간인 힙으로 구성된다. 각각의 구역이 자라면 새로운 페이지를 page fault handler가 추가한다.

### MMU Improvements

**Multi-level Page Maps.**

6.028? OS 강의에서 봤던게 이거인듯. 이를 통해 공간을 절약할 수 있다.

Instead of one page map with 2^20 entries, **virtualize the page table**. One permanently-resident page holds "page directory" which has 1024 entries pointing to 1024-entry partial page tables in _virtual_ memory!

> If the running application is only actively using a small portion of its virtual address space, we may only need a handful of pages to hold the page directory and the necessary page map segments.

**Rapid Context Switching**

원래는 Context가 바뀌면 TLB의 모든 entry들을 무효화해야한다. 좀 낭비임.

> Some MMUs include a **context-number register** whose contents are concatenated with the virtual page number to form the query to the TLB.

따라서 TLB의 태그 필드도 context number를 포함하도록 변형된다.

이제 context를 바꾸려면 OS는 context-number register와 page-table pointer를 교체한다. 이제 TLB의 flush가 필요없고 충분한 공간만 있다면 여러 context를 캐싱할 수 있다.

**캐시와 가상 메모리 함께 사용하기**

방법 1은 CPU와 MMU 사이에 캐시를 배치. VPN에서 PPN의 변환(MMU translation)이 cache miss에서만 발생하지만 context switch가 발생하면 캐시의 모든 entry들이 무효화된다.

방법 2는 MMU와 메인 메모리 상에 캐시를 배치. context switch에 영향을 받지 않지만 MMU translation 비용이 항상 든다.

더 나은 방법. MMU와 cache가 겹쳐서 작동하게 한다. Cache index bit가 page offset의 부분집합이면(전제) 캐시의 동작과 page map 접근이 동시에 일어날 수 있다. Cache의 태그를 물리 페이지 주소와 비교하여 hit/miss를 판단한다.

> By performing the MMU translation and cache lookup in parallel, there’s usually no impact on the average memory access time! Voila, the best of both worlds: a physically addressed cache that incurs no time penalty for MMU translation.

여기는 나중에 다시 읽어보자.

### Worksheet

Page fault 상황에서 메인 메모리에 남은 공간이 없을 때 LRU를 통해 어떤 PPN을 사용해야할지는 다루지만, 정확히 디스크의 어떤 주소의 내용을 가져오는지는 다루지 않는다.

TLB의 LRU와 Page Map의 LRU는 아얘 의미가 다른 듯,,,?

ST하는데 page fault면 dirty가 1이 된다.

## 17. Virtualizing the Processor

### Recap: Virtual Memory

> In the last lecture we introduced the notion of virtual memory and added a Memory Management Unit (MMU) to translate the virtual addresses generated by the CPU to the physical addresses sent to main memory. This gave us the ability to share physical memory between many running programs while still giving each program the illusion of having its own large address space.

> Note that access to a particular mapping context is controlled by two registers. The context-number register controls which mappings are accessible in the TLB. And the page-directory register indicates which physical page holds the top tier of the hierarchical page map. We can switch to another context by simply reloading these two registers.

여러 프로그램이서 CPU를 공유하는 아이디어를 좀 더 살펴보자.

### Processes

**프로세스**라는 추상화를 도입해보자!

> Each process has a "state" that captures everything we know about its execution.

Machine state(레지스터), Program(shared code 포함), context(virtual address space), virtual I/O device, PC, stack을 포함한다. 아래는 I/O 관련된 설명.

> additional information about the process’ input and output activities, such as where it has reached in reading or writing files in the file system, the status and buffers associated with open network connections, pending events from the user interface (e.g., keyboard characters and mouse clicks), and so on.

> There is a special, privileged process, called the operating system (OS), running in its own kernel-mode context. The OS manages all the bookkeeping for each process, arranging for the process run periodically. The OS will provide various services to the processes.

OS에 대한 자세한 내용은 OS 강의에서 살펴보자.

### Timesharing

Beta에서는 interrupt가 발생하면 PC의 supervisor bit가 0인지 확인(user mode 유무)하고, PC+4를 XP에 저장하고, PCSEL을 4로 설정해 특정한 kernel-mode 주소를 PC로 설정한다.

나머지는 소프트웨어로 처리한다. R0-R31의 값을 UserMState라 불리고 메인 메모리에 위치한 OS 자료구조에 저장하고, handler 코드를 실행한다. 코드 실행이 끝나면 UserMState 내용을 복구하고 Reg[XP]-4로 JMP한다.

Beta에서는 주소 0부터 interrupt handler로의 JMP들이 나열되어있다. Reset으로 시작해서 실행 시작되면 자동으로 리셋되는 듯. Common alternative는 PC 값들의 테이블을 마련하고 interrupt hardware가 이에 접근하게 할 수 있다.

> ...handler code in the OS starts and ends with a small amount of assembly-language code to save and restore the state. In the middle, the assembly code makes a C procedure call to actually handle the interrupt.

```c
long TimeofDay;
struct MState { int Regs[31]; } UserMState;

Clock_Handler() {
    TimeOfDay = TimeOfDay + 1;
    // QUANTUM 상수값은 원하는대로 설정
    if (TimeOfDay % QUANTUM == 0) scheduler;
}
```

```s
Clock_h:
    ST(r0, UserMState)
    ST(r1, UserMState+4)
    ...
    ST(r30, UserMState+30*4)

    LD(KStack, SP)
    // After setting up the kernel-mode stack, the assembly-language stub calls the C procedure above to do the hard work.
    BR(Clock_Handler, lp)

    LD(UserMState, r0)
    ...
    LD(UserMState+30*4, r30)
    SUBC(XP, 4, XP)
    JMP(XP)
```

```c
// 인터럽트중에 user-mode 프로세스 상태가 저장된다.
// UserMState의 값은 어셈블리랑 어떻게 연결되지? 주소값인거는 알겠는데 C를 실행시킬 때 어떻게 전달될까?
struct MState { int Regs[31]; } UserMState;

struct PCB {
    struct MState State;
    struct Context PageMap;
    // various state associated with the process’ I/O activities, represented here by a number indicating which virtual user-interface console is attached to the process.
    int DPYNum;
} ProcTbl[N];

// Currently running process
int Cur;

scheduler() {
    ProcTbl[Cur].State = UserMState;
    Cur = (Cur+1)%N;
    UserMState = ProcTbl[Cur].State;
    LoadUserContext(ProcTbl[Cur].PageMap);
}
```

> ...note that since its code runs with the supervisor mode bit set to 1, interrupts are disabled while in the OS.

> Interrupts are allowed during execution of user-mode programs, so if they run amok and need to be interrupted, that’s always possible since the OS is still responding to, say, keyboard interrupts.

Ctrl+Alt+Delete 이런거인듯.

### Handling Illegal Instructions

```s
// hardware interrupt vectors are in low memory
. = 0
BR (I_Reset) // when Beta first starts
BR(I_Illop) // on Illegal Instruction (eg SVC)
BR(I_CIk) // on timer interrupt
BR (I_Kbd) // on keyboard interrupt, use RDCHAR() to get character
BR (I_Mouse) // on mouse interrupt, use CLICK() to get coords

// start of kernel-mode storage
KStack:
    LONG(.+4) // 커널 스택으로의 포인터 값
    STORAGE(256)

// Here's the SAVED STATE of the interrupted user-mode process filled by interrupt handlers
UserMState:
    STORAGE (32) // RO-R30... (PC is in XP/R30!)

N = 16

Cur:
    LONG (0)
ProcTbl:
    STORAGE (N*PCB_Size)
```

**Illop Handler**

```s
// Handler for Illegal Instructions
I_IllOp:
    save_all_regs(UserMState)
    LD(KStack, SP)

    ADDC(XP, -4, r0)
    BR(ReadUserMem, LP) // interpret addr in user context.

    SHRC(r0, 26, r1)
    MULC(r1, 4, r1)
    LD(r1, UU0Tb1, r1)
    JMP(r1)

.macro UUO(ADR) LONG(ADR+0x80000000)
.macro BAD() UUO(UUOError)

// 64-entry dispatch table. 각각은 handler의 주소이다.
UUOTbl:
    Bad()
    UUO(SVC_UUO)
    UUO(swapreg)
    Bad()
    Bad()
    Bad()
    ...
```

> Note that the saved PC+4 value is a virtual address in the context of the interrupted program. So we’ll need to use the MMU routines to compute the correct physical address.

> Selecting a destination from a table of addresses is called **“dispatching”** and the table is called the **“dispatch table”**.

엔트리가 많으면 조건문보다 dispatch table이 더 효율적이다.

```s
// r0에 user-mode 가상 주소가 있다.
ReadUserMem:
    Push(LP) // 백업 + 인자 전달인듯?

    Push(r0)
    BR(VtoP, LP)
    DEALLOCATE(1)
    LD(r0, 0, r0)

    Pop(LP)
    JMP(LP)
```

> In a real operating system, it would be better to save the state of the process in a special debugging file historically referred to as a “core dump” and then terminate this particular process.

```s
.macro swapreg(RA, RC) betaopc(0x02, RA, 0, RC)

swapreg:
    extract_field(r0, 25, 21, r1) // rc feld
    MULC(r1, 4, r1)
    extract_field(r0, 20, 16, r2)
    MULC(r2, 4, r2)
    LD(r1, UserMState, r3)
    LD(r2, UserMState, r4)
    ST(r4, UserMState, r1)
    ST(r3, UserMState, r2)

    BR(I_Rtn) // 다음 섹션에서 다룸
```

### Supervisor Calls

OS에게 필요한 정보/작업을 어떻게 요청할까?

> We’d use these **“supervisor calls”** to access a well-documented and secure OS application programming interface (API).

POSIX가 예시.

Illegal instruction을 실행할 때 transferring control이 되는 것을 활용한다.

> If information is to be returned to the user, the return values can be stored in the temporary storage area, overwriting, say, the saved contents of the user’s R0 register. Then, when the handler completes, the potentially-updated saved register values are reloaded into the CPU registers and execution of the user-mode program resumes at the instruction following the supervisor call.

UUO(Unimplemented User Operation)

```s
// 사실상 매번 Halt() SVC를 재실행하는거다.
HaltH:
// This causes the trapped SVC to be re-executed when the process is eventually rescheduled.
// 예를 들어 ReadCh SVC 요청을 했는데 아직 타이핑이 안되었을 때.
I_Wait:
    LD(UserMState+(4*XP), r0) // 이게 되나? 귀찮아서 이렇게 적은건가
    SUBC(r0, 4, r0)
    ST(r0, UserMState+(4*XP))
// 프로세스는 남은 실행 시간을 포기하고 이걸 실행시킬 수 있다.
YieldH:
    CALL(Scheduler)
    BR(I_Rtn)

I_Rtn:
    restore_all_regs(UserMState)
    JMP(XP) // Good place for debugging breakpoint!
```

> SVCs provide controlled access to OS services and data values and offer **atomic** execution of instruction sequences.

### Worksheet

ReadKey 예시에서 DPYNum이 사용되네.

scheduler는 PC를 바꾸는건 아니고 여기서 리턴한 뒤 JMP(XP)에서 바뀐다.

scheduler는 프로세스간 자원의 공평한 분배에 중요하다.

여기서는 간단하게 몇 밀리초에 한번 생기는 timer interrupt로 scheduler를 실행한다. ILLOP은 별개로 생각하면 될 듯. 각각 마지막에 JMP문이 있음.

3번문제에 언급된 device interrupt는 다음 챕터 보면 잘 알 수 있으려나?

C에서 어셈블리 함수를 호출할 때 어떻게 되는지는 아직 잘 모르겠음.

왜 ReadCh_h는 User를 포인터 접근하고 YieldN_h는 배열 접근하지?

XP는 scheduler 호출에서만 수정된다? 프로세스가 하나면 바뀔 일이 없는건가? SamplePC는 User.Regs[XP]로 PC값을 얻는게 아니라 프로세스 테이블에서 얻어오므로 PC값이 바뀌지 않는건가? 마지막 문제 설명 모르겠음!!!! 프로세스 테이블의 내용은 Scheduler가 실행되면 UserMState에 따라 업데이트된다. Illop을 통한 SVC의 경우 UserMState에 있는 값은 0x1004이지만 이게 Process table에 반영은 안되어있을 수도 있다는 뜻인가??

명령어 실행 중에 interrupt 발생하면 실행중이던거 날리는 듯.

UserMState의 내용은 interrupt가 발생한 당시 레지스터 상태 확인용. Interrupt == Scheduler가 아니다. scheduler에서 UserMState를 사용/조작할 수는 있다. PC값 변경은 UserMState에서 XP를 바꾸어 한다.

### Lab

JMP는 레지스터 값으로!! 상수로 하고싶으면 BR인듯

명령어에서 extract한 것은 레지스터 번호고, 값을 알고싶으면 regs에 백업한걸 LD해서 가져와야함.

명령어에서 extract하고 sign extension 잊지 말기.

LDB는 어떻게 쓰이는지는 모르겠지만 하위 비트 2개는 어디 비트를 load할지 선택하는데 사용하고 주소 접근에서는 버려야함. Load Bit의 약자인가?

피연산자 상수인지 아닌지는(ADD VS ADDC) 제발 확인,,, LD는 두번째 인자로 상수를 받는다.

extract_sign_field 잘 생각한듯.

## 18. Devices and Interrupts

OS가 입출력 기기와 상호작용하는 방법(interrupt handler + kernel buffer)과 유저 모드 프로세스의 요청이 있을 때 어떻게 SVC가 kernel buffer에 접근하는지 알아보자.

### OS Device Handlers

키보드 타이핑 -> 키보드가 CPU에 interrupt 요청 -> interrupt는 현재 프로세스를 중지하고 handler 실행, 버퍼에 문자 넣음.

유저 모드 프로그램에서 ReadKey() SVC 요청, 버퍼에서 꺼내서 반환.

> ... the keyboard handler reads the character from the keyboard and saves it in a kernel buffer associated with the process that has been chosen to receive incoming keystrokes.

Blocking I/O request는 반환값이 있을 때까지 반환하지 않는다.

Non-blocking I/O request는 flag값과 결과값과 함께 즉시 반환한다.

**Interrupt-based Async I/O**. 이벤트 기반 접근 방식을 사용한다. 기기가 OS에 interrupt를 통해 신호를 보낸다. 덕분에 실제 이벤트가 있기 전까지는 CPU 자원을 낭비하지 않고 작동 방식이 유저 프로그램에게 transparent하다.

> Another common approach is to use **“memory-mapped I/O”**, where a portion of the kernel address space is devoted to servicing I/O devices. In this scheme, ordinary LD and ST store instructions are used to access specific addresses

### SVCs for Input/Output

```c
// 시도 1: Supervisor mode(PC[31] == 1)의 코드는 interrupt할 수 없어 버퍼는 영영 채워지지 않는다.
ReadKey_h() {
    int kbdnum = ProcTbl[Cur].DPYNum;
    while (BufferEmpty(kbdnum)) {
        // busy wait loop
    }
    UserMState.Regs[0] = ReadInputBuffer(kbdnum);
}

// 시도 2: 키 입력을 기다리며 프로세스의 time-slice를 낭비하게 된다.
// if there’s a pending interrupt from the keyboard, the device interrupt will supersede the execution of the ReadKey() and the keyboard buffer will be filled.
// Interrupt의 큐같은게 있어야 가능한거겠지??
ReadKey_h() {
    int kbdnum = ProcTbl[Cur].DPYNum;
    while (BufferEmpty(kbdnum)) {
        // busy wait loop
        UserMState.Regs[XP] = UserMState.Regs[XP]-4;
    }
    UserMState.Regs[0] = ReadInputBuffer(kbdnum);
}

// 시도 3
ReadKey_h() {
    int kbdnum = ProcTbl[Cur].DPYNum;
    while (BufferEmpty(kbdnum)) {
        UserMState.Regs[XP] = UserMState.Regs[XP]-4;
        Scheduler();
    }
    UserMState.Regs[0] = ReadInputBuffer(kbdnum);
}
```

작업 완료까지의 시간은 비슷한데 왜 time sharing을 사용하는가? -> 프로세스가 I/O 대기 등의 이유로 자신의 time slice에 대한 효율적인 활용을 하지 못한다면 다른 프로세스에게 양보하는 기능이 필요하다.

보다 복잡한 스케쥴링에서는 프로세스마다 ACTIVE, WAITING 상태가 있고 활성화된 프로세스들을 순회한다. 활성화된 프로세스는 무언가 기다려야되면 keyboard N을 기다린다는 정보들을 PCB에 담은채로 대기로 들어간다. 이후 기기 인터럽트는 대기중인 프로세스를 활성화시킨다.

```c
// UNIX OS
sleep(reason)
wakeup(reason) // Makes active any process in sleep(reason)
```

kbdnum 원리가 궁금하긴 하다.

### Example: Match Handler with OS

이전 Worksheet 내용과 같아서 생략.

### Real Time

빠른 context switching을 통해 더 나은 자원 활용이 가능하다.

하지만 정확히 어느 정도의 시간이 걸릴지 예측하기 어렵다. 실행중인 프로세스의 개수, I/O 이벤트 상태 등등을 알아야한다.

> And we chose to have the OS play the intermediary between interrupt events triggered by the outside world and the user-mode programs where the event processing occurs. In other words, we’ve separated event handling (where the data is stored by the OS) and event processing (where the data is passed to user-mode programs via SVCs).

예정된 시간에 출력이 나오는 것을 보장하기 위해 더 나은 schedule process execution 방법이 필요하다. 이러한 보증을 해주는 시스템을 **real-time system**이라 한다.

Interrupt latency L: 코드 실행 요청과 실제로 실행되는 시간 사이 간격.

L_max + S(Service Time) = D(Deadline)인 L_max가 있다.

> ...In those cases we want our real time system to guarantee that the actual latency is always less than the maximum allowable latency. These critical deadlines give rise to what we call **“hard real-time constraints”**.

Interrupt latency의 요인에는 상태 저장 및 context switch(O/S 설계에서 다룰 수 있음), 인터럽트할 수 없는 긴 명령어(ISA 설계에서 다룸), 인터럽트할 수 없는 이미 다른 인터럽트를 다루고 있는 상태(애는 프로그램 의존적이어서 어려움)가 있다.

> Our goal is to bound and minimize interrupt latency. We’ll do this by optimizing the cost of taking an interrupt and dispatching to the correct handler code. We’ll avoid instructions whose execution time is data dependent. And we’ll work to minimize the time spent in kernel mode.

살펴보겠지만 그럼에도 몇몇 경우에서는 커널 모드에서도 인터럽트가 가능하게 해야하는 경우가 있다.

### Weak Priorities

> ...we see that long-running handlers have a huge impact on the worst-case latency seen by the other devices.

Nonpreemptive/weak priority system: 요청간에 우선순위가 있고 이를 다음 작업을 선택할 때 사용한다. 현재 실행중인 것은 끝까지 실행한다.

Weak priority system의 latency: worst-case service time of all the other devices(요청이 도착했을 때 막 실행을 시작하는 handler가 있을 수도 있다) + service time of all higher-priority devices.

> **“Earliest Deadline”** is a strategy for assigning priorities that is guaranteed to meet the deadlines if any priority assignment can meet the deadlines.

### Strong Priorities

> In a weak priority system the currently-running task will always run to completion before considering what to run next. This means the worst-case latency for a device always includes the worst-case service time across all the other devices.

> We need to introduce a **preemptive priority system** that allows lower-priority handlers to be interrupted by higher-priority requests. We’ll refer to this as a “strong” priority system

이전 슬라이드인 Scheduling of Multiple Devices에서 몇몇 assumption이 있었는데 이거때문에 preemptive priority system의 latency를 계산할 때 우선순위 높은 애 때문에 낮은 애가 끝없이 밀리는 경우는 다루지 않는듯?

Strong priority system을 Beta 하드웨어에 적용해보자. PC[31]을 PC[31:29](PRI)로 늘려 총 프로세스당 8개의 우선순위를 명시할 수 있게 하자. Interrupt를 요청할 때 3-bit 우선순위도 명시하도록 한다. 이후 PC의 우선순위와 비교해서 크면 인터럽트를 받아들인다. 받아들인다면 이전의 PC와 PRI 정보를 XP에 저장한다. 그런데 이러면 인터럽트를 인터럽트한게 다시 인터럽트당하면 어떻게 구현하지??

아무튼 strong priority system을 쓴다면 latency만으로는 부족하다. 중간에 preempted될 수 있기 때문에 completion time도 봐야한다.

우선순위가 낮으면 끝없이 늘어질 수도 있다. 이런 경우는 요청을 제한시간내에 처리할 수 있는 CPU 사이클이 부족하기 때문이다. 이와 관련된 계산식들이 있는데, 글보단 표로 보는게 나을 것 같으니 슬라이드 참고.

### Example: Priorities in Action!

weak 4번 계산이 이게 맞나??

strong에서는 weak와 달리 하던 일이 끊길 수도 있기 때문에 maximum service time을 위해 CPU 시간의 사용 정도를 분석해야한다. 쪼개져도 되는걸 보면 이전 실행 결과를 저장해놓는다보다. 여기서도 context switch랑 비슷한듯?

> Each task might have to wait for the longest-running lower-priority handler to complete plus the service times of any other higher-priority tasks plus, of course, its own service time.

위에 뭔가 이상함 frequency가 주어져야 확실히 알 수 있지 않나? longest-running lower-priority의 이유를 잘 모르겠음.

### Summary

> Real-life computer systems usual implement strong priorities and support a modest number of priority levels, using a weak priority system to deal with multiple devices assigned to the same strong priority level. This seems to work quite well in practice, allowing the systems to meet the variety of real-time constraints imposed by their I/O devices.

## Worksheet

Worst-case completion time에는 자기 자신의 수행 시간도 더해야한다.

Percentage idle time for this system은 weak/strong 상관없이 같을 것 같은게, 어차피 사용하는 CPU 자원의 양은 동일하고 분배 방식이 다르기 때문이다. 급한 일을 얼마나 먼저 하는지의 차이.

태스크의 rate 주기 내에 다른 우선순위가 높은 일들이 여러개 있을 수 있지만 반드시 이 여러개들이 끝나고 해당 태스크가 수행되는 아님. 사이에 틈이 있을 수도!

weak에서는 rate를 신경쓰지 않아도 되는건가?? strong에서는 rate에 따라 뒤로 밀리지만, weak은 안밀리는 차이?

## 19. Concurrency & Synchronization

### Interprocess Communication

어플리케이션을 여러 프로세스로 구성하여 동시성, 프론트/백 구분, 캡슐화를 이룰 수 있다.

어떻게 프로세스간 통신을 구현할 수 있을까?

프로세스가 같은 메모리에서 실행된다면 같은 물리적 페이지를 공유하여 메모리 데이터를 공유하는 것이 용이하다. 이를 위해 synchronizatino primitives를 제공하면 편리하다.

메시지를 다른 프로세스로 전달하기 위한 OS supervisor calls를 추가하는 방법도 있다. Shared memor보다 오버헤드는 있지만 makes the application programming independent of whether the communicating processes are running on the same physical processor?

이번 강의에서는 producer-consumer problem을 예시로 들 것이다.

생산자/소비자 시스템에는 **precedence constraints**가 있다. 생산되지 전에 소비될 수 없고, 소비하기 전에 새로 생산할 수 없다. send_i < rcv_i, rcv_i < send_i+1. 부등호가 아니라 발생 순서를 나타낸다는 것 주의.

이대로면 계산에 가변적인 시간이 걸리면 비효율적이게 된다. 생산자와 소비자의 의존성을 줄이는 방법을 찾아보자.

FIFO 버퍼를 사용하자. 생산자는 소비자보다 버퍼의 크기인 N만큼 앞설 수 있다. rcv_i < send_i+N.

```c
// Shared Memory
char buf[N];
int in = 0; out = 0;

// Producer
send(char c) {
    buf[in] = c;
    in = (in+1)%N;
}

// Consumer
char rcv() {
    char c;
    c = buf[out];
    out = (out+1)%N;
    return c;
}
```

위 코드대로면 두개의 precedence constraints중 어떤 것도 지켜지지 않는다. 이를 위해 we’ll introduce a new programming construct that we’ll use to provide the appropriate inter-process synchronization.

### Semaphores

> In the early 1960’s, the Dutch computer scientist Edsger Dijkstra proposed a new abstract data type called the semaphore, which has an integer value greater than or equal to 0

세마포어는 프로세스들에게 공유되는 메모리에 위치하여 그들간의 작업을 조율하는 역할을 한다.

WAIT(혹은 P)는 값이 양수일 때까지 기다리고, 이후 값을 1 줄이고 다음으로 넘어간다. SIGNAL(혹은 V)은 1 증가시킨다.

SEMANTIC GUARANTEE: K로 초기화된 세마포어는 signal(s)\_i < wait(s)\_i+k 을 강제한다.

```c
// 공유 자원의 맥락에서 세마포어를 활용할 수 있다.

// Shared Memory
semaphore s = K; // 자원의 개수 K

// Using resources:
wait(s);
...
signal(s);

// Invariant: Semaphore value = number of resources left in pool
```

```c
// Precedence contraint중에 하나를 완료했다.
// send_i < rcv_i

// Shared Memory
char buf[N];
int in = 0; out = 0;
semaphore chars = 0;

// Producer
send(char c) {
    buf[in] = c;
    in = (in+1)%N;
    signal(chars);
}

// Consumer
char rcv() {
    char c;
    wait(chars);
    c = buf[out];
    out = (out+1)%N;
    return c;
}
```

rcv_i < send_i+N를 하는 방법을 알아보자. Flow Control Problems.

```c
// rcv_i < send_i+N

// Shared Memory
char buf[N];
int in = 0; out = 0;
semaphore chars=0; space=N;

// Producer
send(char c) {
    wait(space);
    buf[in] = c;
    in = (in+1)%N;
    signal(chars);
}

// Consumer
char rcv() {
    char c;
    wait(chars);
    c = buf[out];
    out = (out+1)%N;
    signal(space);
    return c;
}
```

이제 여러개의 생산자와 소비자가 있을 때 무슨 일이 일어나는지 알아보자.

### Atomic Transactions

```s
// Process 1
LD(R10, balance, R0)

// Process 2
LD(R10, balance, R0)
SUB(R0, R1, R0)
ST(R0, balance, R10)

// Process 1
SUB(RO, R1, R0)
ST(R0, balance, R10)
```

> For certain code segments, called **critical sections**, we would like to ensure that no two executions overlap.

> This constraint is called **mutual exclusion**.

> The combination of the semaphore to enforce the mutual exclusion constraint and the critical section of code implement what’s called a **“transaction”**. A transaction can perform multiple reads and writes of shared data with the guarantee that none of the data will be read or written by other processes while the transaction is in progress.

```c
// a <> b, a precedes b or b precedes a. They don't overlap.
semaphore lock = 1;

Debit(int account, int amount) {
    wait(lock);
    t = balance[account];
    balance[account] = t - account;
    signal(lock);
}
```

Lock의 granularity를 잘 정하는 것도 관건이다.

> The notion of transactions on shared data is so useful that we often use a separate system called a database that provides the desired functionality. Database systems are engineered to provide low-latency access to shared data, providing the appropriate transactional semantics. The design and implementation of databases and transactions is pretty interesting - to follow up, I recommend reading about databases on the web.

이제 이전 생산자/소비자 문제의 풀이를 살펴보면 버퍼에 쓰는 작업이 atomic하지 않음을 알 수 있다.

```c
// Shared Memory
char buf[N];
int in = 0; out = 0;
semaphore chars=0; space=N; lock=1;

// Producer
send(char c) {
    wait(space);
    wait(lock);
    buf[in] = c;
    in = (in+1)%N;
    signal(lock)
    signal(chars);
}

// Consumer
char rcv() {
    char c;
    wait(chars);
    wait(lock);
    c = buf[out];
    out = (out+1)%N;
    signal(lock);
    signal(space);
    return c;
}

// 생산자와 소비자가 서로 다른 인덱스를 사용하기에 두개의 lock을 사용할 수도 있다.
```

세마포어는 synchronization primitive인듯?

### Semaphore Implementation

세마포어를 구현하려면 세마포어가 필요한데 어떻게할까?

> ...if we’re running on a timeshared processor with an uninterruptible OS kernel, we can use the supervisor call (SVC) mechanism to implement the required functionality.

> We can also extend the ISA to include a special test-and-set instruction that will let us implement a simple lock semaphore, which can then be used to protect critical sections that implement more complex semaphore semantics. Single instructions are inherently atomic and, in a multi-core processor, will do what we want if the shared main memory supports both reading the old value and writing a new value to a specific memory location as a single memory access.

> There are other, more complex, software-only solutions that rely only on the atomicity of individual reads and writes to implement a simple lock. For example, see “Dekker’s Algorithm” on Wikipedia.

처음 두 방법을 살펴보자.

```c
// 그나저나 _h 는 무슨 뜻이지
// SVC call은 커널 모드에서 수행되기에 interrupt될 수 없다.
wait_h() {
    int *addr;
    addr = VtoP(User.Regs[R0]); // get arg, address of the semaphore location
    if (*addr <= 0) {
        User.Regs[XP] = User.Regs[XP] -4;
        sleep(addr); // mark the process as inactive until the corresponding WAKEUP call is made.
    } else {
        *addr = *addr - 1;
    }
}

signal_h() {
    int *addr;
    addr = VtoP(User.Regs[R0]);
    *addr = *addr + 1;
    wakeup(addr);
}

// Note that the code makes no provision for fairness.
// If fairness is desired, WAIT could maintain a queue of waiting processes and use the queue to determine which process is next in line, independent of scheduling order.
```

세마포어의 하드웨어적 구현. 많은 ISA들이 TEST-and-CLEAR와 같은 명령어를 지원한다. 메모리 위치를 읽어 레지스터에 저장하고 0으로 설정한다. 이때 메모리가 read-and-clear 작업을 atomicity하게 지원해야한다.

```s
wait: TCLR(R31, lock, R0)
      BEQ(R0, wait)
      ... critical section ...
      CMOVE(1, R0)
      ST(R0, lock, R31)

// 양수값 설정해주는거는 생략한건가?
```

### Deadlock

> ...synchronization involving multiple resources requires a bit more thought.

```c
Transfer(int account1, int account2, int amount) {
    wait(lock[account1]);
    wait(lock[account2]);
    balance[account1] -= amount;
    balance[account2] += amount;
    signal(lock[account2]);
    signal(lock[account1]);
}
```

그나저나 wait과 signal이 대칭인 이유가 있었나?

Dining Philosophers problem.

데드락에 필요한 조건들

1. Mutual exclusion, where a particular resource can only be acquired by one process at a time.

2. Hold-and-wait, where a process holds allocated resources while waiting to acquire the next resource.

3. No preemption, where a resource cannot be removed from the process which acquired it. Resources are only released after the process has completed its transaction.

4. Circular wait, where resources needed by one process are held by another, and vice versa.

> ...if all the processes in the system can agree upon a global ordering for the resources they require, then acquire them in order, there will be no possibility of a deadlock caused by a hold-and-wait cycle.

위와 같은 방법은 cooperate하는 모든 프로세스를 수정할 수 있을 때 가능하다.

Detection and recovery 방법도 있다. 데이터베이스에서 활용됨.

데드락에 대해서는 이 강의에서 간단하게만 다루는 듯.

### Worksheet

음수 세마포어는 왜 안되지? 됐으면 2-B 풀기 편했을 것 같은데.

> However, almost all practical use of semaphores is a special case where the counter is initialized to 1, and where they are used as simple mutual exclusion with only one user allowed in the critical region. Such a semaphore is often called a "mutex" semaphore for MUTual EXclusion.
>
> I've never really seen anybody use the more complex case of semaphores, although I do know of cases where it can be useful. For example, one use of a more complex semaphore is as a "throttle", where you do something like this:
>
> ```c
> /* Maximum concurrent users */    #define MAX_CONCURRENT_USERS 20
> struct semaphore sem;
>
> init_sema(&sem, MAX_CONCURRENT_USERS);
> ```
>
> and then each user does a down() on the semaphore before starting an operation. It won't block until you have 20 users - you've not created a mutual exclusion, but you HAVE created a throttling mechanism. See?
>
> https://stackoverflow.com/questions/20656295/what-is-general-semaphores-range

세마포어의 global ordering이 있으면 데드락은 발생할 수 없다.

## 20. System-level Communicaition

### System-level interfaces

> ...important part of the system architecture is the interfaces.

> Interfaces typically deserve more engineering attention than the technologies they interface...

> Today’s lecture topic is figuring out the appropriate interface choices for interconnecting system components.

> As we’ll see, engineering considerations have led to the widespread adoption of general-purpose unidirectional point-to-point communication channels.

### Wires

예전에는 와이어를 간단하게 추상화해도 문제가 없었지만, 소형화 고속화 이후 중요해졌다.

> Distance and signal propagation matter — real-world wires are, in fact, fairly complex components!

와이어를 묘사하는 4 parameters

- R tells us the resistance of the conductor. It’s usually negligible for the wiring on printed circuit boards, but it can be significant for long wires in integrated circuits.
- L represents the self-inductance of the conductor, which characterizes how much energy will be absorbed by the wire’s magnetic fields when the current flowing through the wire changes.
- The conductor and reference node are separated by some sort insulator (which might be just air!) and hence form a capacitor with capacitance C.
- Conductance G represents the current that leaks through the insulator. Usually this is quite small.

'Electrical Model for Real Wires'에 회로도 참고하기.

> ... we can describe the behavior of the wires using a single component called a transmission line which has a characteristic complex-valued impedance Z_0.

자세히는 모르겠지만 전파 속도는 LC^(-1/2)m/s이고 Z_0은 L/C^(1/2)이다.

와이어 끝부분에 아무 처리도 안하면 신호가 반사되어 echo되니 terminate the wire with a resistance to ground해야한다.

이전 전송에서 남은 에너지때문에 현재 전송이 오염될 수 있다.

> ...energy will reflect off of any impedance discontinuity

전기공학 내용은 여기서 끝 ㅠㅠ

같은 시간에 정보의 위치가 바뀌면 communication, 다른 시간에 같은 위치에 있는건 storage.

Communication에는 시간이 소모되고 이를 timing model에 반영시켜야한다.

앞선 강의에서는 t_PD만을 고려했지만 게이트 사이에서 전파되는 시간도 고려해야된다. Long/heavily-loaded outputs는 전파가 오래 걸릴 것이다.

오늘날에는 시스템 수준에서 컴포넌트들을 연결하기 위한 와이어도 화두니 이것도 다뤄보자.

### Buses

Backplane bus. 공통의 backplane(motherboard)에 CPU, 메모리등을 플러깅하면 전원, 공용 시스템 클럭, 커뮤니케이션을 위한 와이어가 제공된다. CPU는 나머지들과 소통할 수 있다.

- Address wires to select different communication end points on the add-in card.

- Data wires for transferring data to and from the CPU.

- Some number of control wires that tell the add-in card when a particular transfer has started and that allow the add-in card to indicate when it has responded.

이 와이어들을 **버스**라고 통칭한다.

> **“Bus”** is system architect jargon for a collection of wires used to transfer data using a pre-determined communication protocol.

> The component initiating the transaction is called the **bus master** who is said to “own” the bus.

> The intended recipient, called the **slave**, is watching the bus lines looking for its address at each sample edge.

이러한 버스 방식은 transaction이 50MHz정도로 아주 빠르지 않을 때 쓸만하다.

Transaction이 많아지면서 propagation time, skew, reflections & standing waves와 같은 문제들이 발생했다.

> Eventually buses were relegated to relatively low-speed communication tasks and a different approach had to be developed for high-speed communication.

### Point-to-point Communication

네트워크 기술은 cm 단위가 아닌 m 단위로 컴포넌트들을 연결할 수 있도록 발전했다. 추상화된 레이어들로 구성된다.

> The lowest-level physical layer is responsible for transmitting and receiving an individual packet of bits.

> The network layer deals with the addressing and routing of packets.

> The transport layer is responsible for providing the reliable communication of a stream of data, dealing with the issues of discarded or out-of-order packets.

> A key idea in the networking community is the notion of building a reliable communication channel on top of a “best efforts” packet network. Higher layers of the protocol are designed so that its possible to recover from errors in the lower layers. This has proven much more cost-effective and robust than trying to achieve 100% reliability at each layer.

> Experience in the network world has shown that the fastest and least problematic communication channels have a single driver communicating with a single receiver, what’s called a point-to-point link.

> With some cleverness, it turns out that we can recover the timing information from the received signal assuming we know the nominal clock period at the transmitter.

> The transmitter adds a training sequence of bits at the front of packet to ensure that the receiver’s phased-lock loop is properly synchronized before the packet data itself is transmitted.

### System-level Interconnect

이에 따라 네트워크에서 각각의 링크는 두 개의 호스트만을 연결하고, 스위치나 라우터들이 많다. System-level connection도 point-to-point link에 패키지를 라우팅하기 위한 스위치들로 구성된다. 아무튼 이더넷 시절처럼 와이어 하나를 공유하지 않는다.

> So knowledge from the networking world has reshaped how components communicate on the motherboard, driving the transition from parallel buses to a handful of serial point-to-point links.

> PCI Express (PCIe) is often used as the communication link between components on the system motherboard.

### Communication Topologies

BUS: Throughput O(1), Latency O(1), Cost O(n)

RING: Throughput O(n), Latency O(n), Cost O(n)

Throughput이 잘 와닿지 않는데 point-to-point link의 개수에 비례한다고 한다.

> Ring topologies are useful when message latency isn’t important or when most messages are to the component that’s immediately downstream, i.e., the components form a processing pipeline.

COMPLETE GRAPH: Throughput O(n^2), Latency O(1), Cost O(n^2)

> A variant of the complete graph is the crossbar switch where a particular row and column can be connected to form a link between particular A and B components with the restriction that each row and each column can only carry 1 message during each time unit.

CROSSBAR SWITCH: Throughput O(n), Latency O(1), Cost O(n^2) - Switch 때문.

> In mesh networks, components are connected to some fixed number of neighboring components.

2-Dimensional Meshes: Throughput O(n), Latency O(n^1/2), Cost O(n)

3-Dimensional Meshes: Throughput O(n), Latency O(n^1/3), Cost O(n)

HYPERCUBE, BINARY TREE...

> ...tree network, with the clever innovation that the links towards the root of the tree had a higher message capacity.

### Summary

- Point-to-point links are in common use today for system-level interconnect, and as a result our systems are faster, more reliable, more energy-efficient and smaller than ever before.
- Multi-signal parallel buses are still used for very-high-bandwidth connections to memories, with a lot of very careful engineering to avoid the electrical problems observed in earlier bus implementations.
- Wireless connections are in common use to connect mobile devices to nearby components and there has been interesting work on how to allow mobile devices to discover what peripherals are nearby and enable them to connect automatically.
- The upcoming generation of multi-core chips will have 10’s to 100’s of processing cores. There is a lot ongoing research to determine which communication topology would offer the best combination of high communication bandwidth and low latency. The next ten years will be an interesting time for on-chip network engineers!

추가 챕터 느낌이라서 그런지 이해하기 어려웠다 ㅎㅎ;;

## 21. Parallel Processing

### Instruction-level Parallelism

Time / Program = 프로그램당 명령어 \* CPI \* t_CLK

ISA와 컴파일러는 프로그램 당 명령어를 결정짓는다. 파이프라인은 t_CLK를 줄인다. CPI는 CPI_ideal과 CPI_stall로 구성되는데 stall은 data hazard, control hazard, memory latency등이 결정짓는다.

지난 수업 때 다룬 5-stage pipeline은 무난하지만 CPI_ideal의 상한이 1이고, 곱셈이나 캐시 접근과 같은 무거운 작업이 t_CLK를 늘리며, 작업 순서가 고정되었기에 비의존적임에도 불구하고 앞선 작업이 모든 뒤의 작업을 미룬다는 단점이 있다.

개선 방법을 알아보자.

파이프라인을 깊게하여 t_CLK를 줄인다. MEM을 두 단계로 나누는 것도 예시인데, data hazard에서 NOP 버블이 늘어나므로 CPU_stall이 길어지기는 한다. 이 방법은 더 많은 **명령어를 병렬**로 실행한다.

다만 파이프라인 단계마다 오버헤드가 있다. 레지스터 propagation delay, setup/hold time, clock skew, inequalities between stages... T / (T/N + O)는 파이프라인이 깊어질수록 T/O에 가까워지고 결국 오버헤드가 지배한다. 일정 수준 이상으로는 유익이 없다.

깊은 파이프라인으로 t_CLK를 줄이고, 넓은 파이프라인으로 CPI_ideal을 늘리며, 비순차적 실행으로 CPI_stall을 줄인다. 동시에 여러 명령어가 실행되므로 control hazard가 커지는데 이를 branch prediction으로 극복한다. 이러한 property(방법?)들을 **instruction-level parallelism**이라 한다.

실행 순서는 read-after-write(RAW)가 제한하며 bypassing을 활용할 수 있는 경우가 있다.

WAW와 WARs는 renaming으로 해결할 수 있다. 여기서는 자세히 안다룸.

**Superscalar pipelines**

> ...what’s the right tradeoff between increased circuit costs and increased concurrency? As a data point, the Intel Nehalem core can complete up to 4 micro-operations per cycle...

[Branch predictor](https://en.wikipedia.org/wiki/Branch_predictor)

> If an instruction needs the result of an earlier instruction as an operand, the dispatcher has identified which functional unit will be producing the result. The instruction waits in a queue until the indicated functional unit produces the result and when all the operand values are known, the instruction is finally taken from the queue and executed. Since the instructions are executed by different functional units as soon as their operands are available, the order of execution may not be the same as in the original program.

> After execution, the functional units broadcast their results so that waiting instructions know when to proceed. The results are also collected in a large reorder buffer so that that they can be retired (i.e., write their results in the register file) in the correct order.

겁나 신기함.

Out-of-order, superscalar pipeline은 더 깊어지면 CPI_stall와 timing overhead가 커져 이득이 없다. Out-of-order 실행도 더 늘리면 분기 예측 실패의 손실이 늘어나고 메인 메모리를 더 빠르게 하기 힘들며 전력을 많이 소비한다. 설계하기 복잡하다!!

Data-Level Parallelism(Vector extensions, GPUs), Thread-Level Parallelism(Multiple threads and cores)로 눈을 돌렸다.

### Data-level Parallelism

데이터나 벡터나 행렬 형태로 입력되는 경우가 많으며 이 때 계산은 같은 종류의 작업을 여러번 반복하는 형태가 많다.

따라서 CPU의 datapath 부분을 복제해서 특수 목적 벡터 프로세서를 만들 수 있다. 데이터는 메모리에서 큰 블록 형태로 가져와진다. 모든 datapath는 같은 명령어를 실행한다.

> Executing a single instruction on a machine with N datapaths is equivalent to executing N instructions on a conventional machine with a single datapath. The result achieves a lot of parallelism without the complexities of out-of-order superscalar execution.

```s
// for i in range(16) x[i] = a[i] + b[i]
// Beta assembly
      CMOVE (16, RO)
loop: LD(R1, 0, R4)
      LD(R2, 0, R5)
      ADDC(R1, 4, R1)
      ADDC(R2, 4, R2)
      ADD(R4, R5, R6)
      ST(R6, 0, R3)
      ADDC(R3, 4, R3)
      SUBC(RO, 1, RO)
      BNE(RO, loop)

// Equivalent vector assembly
LD.V(R1, 0, V1)
LD.V(R2, 0, V2)
ADD.V(V1, V2, V3)
ST.V(V3, 0, R3)
```

이러한 성능 향상은 코드를 vectorize할 수 있는 프로그램에 한정된다. 오디오, 비디오 인코딩 디코딩과 같은 디지털 신호 프로세싱 등등...

```s
// for i in range(16) if a[i] < b[i], c[i] += 3

LD.V(RI, 0, V1) // load a[i]
LD.V(R2, 0, V2) // load b[i]
LD.V(R3, 0, V3) // load c[i]
CMPLT.V(V1, V2) // set local predicate flags
// predicated instructions perform the
// indicated operation if the local predicate
// flag istrue or isfalse.
ADDC. V.iftrue (V3, 3, V3)
```

위와 같은 instruction prediction은 다른 ISA에서도 많이 활용한다. 32-bit ARM ISA의 거의 모든 명령어는 conditionally 실행될 수 있다.

> The power of vector processors comes from having 1 instruction initiate N parallel operations on N pairs of operands.

> GPU datapaths are typically specialized for 32- and 64-bit floating point operations found in the algorithms needed to display in real-time a 3D scene represented as billions of triangular patches as a 2D image on the computer screen.

### Thread-level Parallelism

가능한 병렬화를 통해 추가적인 코어를 사용할 수 있다면 linear relationship between increased performacne vs. increased cost가 가능하다. 핵심은 큰 추가비용 없이 작업을 여러개로 나누어 나눠진 작업간 최소한의 소통으로 독자적으로 계산을 수행할 수 있는지.

암달의 법칙을 통해 계산의 많은 부분을 차지하는 부분을 개선해야 큰 성능 향상을 일으킴을 알 수 있다. 따라서 병렬화할 수 있는 프로그램의 비중을 높여야한다.

암달의 법칙 식을 활용해 성능 향상 목표치로부터 병렬화되어있어야하는 프로그램의 비중을 구할 수 있다.

> Using multiple independent cores to execute a parallel task is called thread-level parallelism (TLP), where each core executes a separate computation “thread”.

여기서 쓰레드는 OS에서 쓰레드랑 다른거겠지?

TLP는 전에 본 vector machine보다 유연하다.

쓰레드의 수가 적으면 메인 메모리를 공유해서 소통할 수 있다. 다음 챕터에서 살펴볼 것이다. 코어 2~12개 정도에서 사용할 수 있다.

코어가 10~100이 되면 쓸 수 없는데 메모리 bandwidth를 초과하기 때문이다. Message passing을 활용한다.

> There’s a standardized message passing interface (MPI) and specialized, very high throughput, low latency message-passing communication networks (e.g., Infiniband) that make it easy to build high-performance computing clusters.

### Shared Memory & Caches

평균 메모리 접근 시간을 줄이기 위해 각각의 코어는 자신만의 캐시를 지니고 있다. 메인 메모리 접근을 줄이기 위해 write-back 전략을 사용한다.

모든 코어가 메인 메모리의 내용을 공유하는 것이 목적이다. 하지만 캐시로 인해 코어가 다른 정보를 보게 된다.

> Semantic constraint: Result of executing N parallel threads should correspond to _some_ interleaved execution on a single processor.

위 notion을 **sequential consistency**라 한다. 이를 만족해야 프로그래머가 시스템이 하드웨어 가속되는 timesharing을 제공한다고 믿게 된다.

([Memory Barriers: a Hardware View for Software Hackers](http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf). Very readable discussion of memory semantics in multicore systems.)

고치는 법 중 하나는 sequential consistency를 포기하는 것.

> An alternative memory semantics is “weak consistency”, which only requires that the memory operations from each thread appear to be performed in the order issued by that thread. Memory operations from different threads may overlap in arbitrary ways (not necessarily consistent with any interleaving).

Sequential consistency와 크게 뭐가 다른지는 잘 모르겠다 ㅠ

사실 지금과 같은 멀티코어 캐시 시스템에서는 weak consistency도 보장하지 못한다.

### Cache Coherence

> The fix is to provide the necessary communications over a shared bus that’s watched by all the caches. A cache can then “snoop” on what’s happening in other caches and then update its local state to be consistent. The required communications protocol is called a **“cache coherence protocol”**.

실제 공유되는 정보가 바뀌었을 때만 통신하도록 하는게 프로토콜의 목표.

## 22. Wrap-up

마지막 Lab 두 개는 안함. 컴구 수업이 우선이다 ^^;
