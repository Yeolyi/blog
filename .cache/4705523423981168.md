---
title: 알고리즘 문제 해결 전략
---

lexiographical_compare.

부호 없는 정수형과 있는 정수형을 연산하면 없는 정수형으로 프로모션된다??

!@3/size_t.cpp@!

STL lower_bound, upper_bound

https://www.solipsys.co.uk/new/BinarySearchReconsidered.html

https://www.cs.cmu.edu/~15122-archive/n17/lec/06-binsearch.pdf

집합 덮개 문제(set cover)는 발견된 다항 시간 알고리즘이 없다.

소인수분해와 같이 입력의 크기에 따라 수행 시간이 달라질 수 있다. O(N)같아보이지만 알고리즘의 수행 시간과 입력이 메모리에서 차지하는 공간의 관계를 생각해보면 비트 수가 하나 증가할 때마다 알고리즘의 최대 수행 시간은 두 배로 증가한다. 입력의 크기를 입력이 차지하는 비트 수로 정의하면 입력의 크기에 대해 지수 시간이 걸린다.

반복문 불변식은 반복문이 실행되는 항상 성립한다.

```c
void insertionSort(vector<int>& A) {
    for (int i=0; i<A.size(); ++i) {
        // 불변식 a: A[0...i-1]은 이미 정렬되어있다.
        int j =i;
        while (j > 0 && A[j-1] > A[j]) {
            // 불변식 b: A[j+1...i]의 모든 원소는 A[j]보다 크다.
            // 불변식 c: A[0...i] 구간은 A[j]를 제외하면 정렬되어 있다.
            swap(A[j-1], A[j]);
            --j;
        }
    }
}
```

## 6. 무식하게 풀기

브루트 포스 혹은 완전 탐색이란 가능한 모든 후보들을 순회하며 어떤 후보가 요구사항은 만족시키는지 확인하는 것이다.

최적화 문제(optimization problem)란 적당한 답들 사이에서 최선의 답을 찾아내는 문제이다.

무식해보이지만 간단한 해결책인 완전 탐색을 간과해서 문제를 어렵게 푸는 경우가 있다.

재귀 호출은 완전 탐색을 구현할 때 유용한 도구이다.

재귀 함수의 기저 사례(base case)란 더 이상 쪼갤 수 없는 가장 작은 작업으로 이때 재귀 함수는 값을 곧바로 반환하는 조건문을 포함한다.

잘못된 입력이나 벗어난 범위에 대한 경우도 기저 사례로 채택하여 재귀함수 상단 조건문에서 처리하면 재귀 함수를 호출할 때 이러한 오류를 검사할 필요가 없다. 재귀 함수는 여러 곳에서 호출되기에 이러한 처리가 유용하다.

완전 탐색에서 같은 답을 중복으로 세는 문제는 사전순과 같이 답에 대한 형태를 강제하여 해결할 수 있다.

재귀 호출에서 '문제'란 항상 수행해야 할 작업과 그 작업을 적용할 자료의 조합을 의미한다?? 문제와 부분 문제??

```cpp
// 다중 배열 초기화
const int coverType[4][3][2] = {
    { { 0, 0 }, { 1, 0 }, { 0, -1 }},
    { { 0, 0 }, { 1, 0 }, { 0, -1 }},
    { { 0, 0 }, { 1, 0 }, { 0, -1 }},
    { { 0, 0 }, { 1, 0 }, { 0, -1 }},
}
```

문제의 답이 하나가 아니라 여러 개이고, 그 중에서 어떤 기준에 따라 가장 '좋은'답을 찾아 내는 문제를 최적화 문제라 한다.

재귀 호출할 때 원상복구하고 return하면 pass by reference로도 잘 되는 테크닉.

!@6/next_permutation.cpp@!

[순열 (Permutation) 알고리즘의 모든 것](<https://rimkongs.tistory.com/212#:~:text=그럼%20next_permutation이%20최종적으로%20나왔다.&text=따라서%20총%20시간복잡도는,(N)%20시간이%20걸린다.>)

## 7. 분할 정복

DP는 겹치고 분할 정복은 안겹치는거였나?

분할 정복이 일반적인 재귀 호출과 다른 점은 문제를 한 조각과 나머지 전체로 나누는 대신 거의 같은 크기의 부분 문제로 나누는 것입니다.

카라츠바 생략

```cpp
string::iterator& it;
```

!@7/1725.cpp@!

25장 상호 배타적 집합을 사용한 풀이 거기 읽고 생각해보기.

## 8. 동적 계획법

!@8/memset.cpp@!

'"원하는 답이 존재하는가?" 라는 질문을 완전 탐색으로 구할 때 가장 문제가 되는 것은, 원하는 답은 없는데 전체 답의 개수는 무지막지하게 많은 경우입니다.'

완전 탐색이 만드는 경우의 수 >> 함수 입력의 수 면 비둘기집 원리에 의해 겹치는 경우가 많다.

재귀 호출을 사용하지 않은 DP를 반복적 DP라 한다.

와일드카드 -> 최대한 캐싱한 정보를 사용하도록 바꾼다. 정보를 캐싱하도록 바꾼다. 루프로 인한 O(n)을 재귀 호출로 해결.

DP는 최적회 문제의 해결에 가장 일반적으로 사용된다. 최적화 문제에 특정 성질이 성립하면 단순 메모이제이션 적용보다 효율적으로 동적 계획법을 구현할 수 있다.

이미 결정한 것에 대한 정보는 배제한다. 이때 **최적 부분 구조(optimal substructure)**가 성립해야한다.

순증가(strictly increasing)/단조증가(monotonically increasing)

!@8/lis.cpp@!

lower_bound, upper_bound. a <= x < b 느낌인듯.

```cpp
numeric_limits<long long>::min();
```

두 수가 번갈아 등장하는지 확인하려면 M[i] == M[i%2]와 같은 짓이 가능.

양자화 - 분할의 개수는 100C10정도인데 겹치는 부분 덕분에 100\*10으로 해결 가능한 느낌

경우의 수 - 배타적이고 포괄적이어야한다.

함수 반환값이 모듈러인 경우 뺄셈할 때 음수가 나올 수 있어서 MOD를 더해줘야한다.

**마르코프 연쇄**

- 유한개의 상태
- 매 시간마다 상태가 변화
- 상태 a에서 b로 갈 확률은 a에만 좌우됨

두니발 박사 문제는 백준에 비슷한거 있으면 풀면 좋을듯

## 9. 동적 계획법 테크닉

배낭 문제 - 0/1 배낭 문제(하나만 고를 수 있음), 여러개 담는 배낭 문제, 쪼개서 담을 수 있는 분수 배낭 문제(fractional knapsack problem - 그리디)

마르코프 연쇄로 원문을 모델링하는 것은 단순하면서도 어느 정도는 현실을 반영하기 때문에, 아무 가정도 하지 않는 것보다는 나은 결과를 만들어 냅니다. 따라서 마르코프 연쇄는 정확도와 시간 복잡도 사이의 트레이드 오프라고 할 수 있습니다.

P(B∣A)= P(A|B)P(B) / P(A)

마르코프 연쇄를 통해 생성된 데이터들을 직접 볼 수 없고 오류가 있는 별도의 관찰자를 통해 관찰해야 하는 모델을 은닉 마르코프 모델(Hidden Markov Mode, HMM)이라 한다.

HMM의 관측 결과가 주어질 때 가장 가능성 높은 실제 상태를 계산하는 방법으로는 비터비 알고리즘(Viterbi algorithm)이 있다.

!@9/stringinit.cpp@!

k번째 lis 다시 읽어보기

20!도 long에 담김!!

!@9/next_permutation_dup.cpp@!

웨브바짐 다시 읽어보기.

게임이론에서 impartial game(대칭 게임)은 각 참가자가 둘 수 있는 수가 완전히 똑같다.

turn이 'o'아님 'x'고 이걸 반전시키려면 'o'+'x'-turn을 해도 된다.

> Minmax (sometimes Minimax, MM or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for minimizing the possible loss for a worst case (maximum loss) scenario.

반복문을 이용한 동적 계획법을 반복적(iterative) 동적 계획법이라 한다. Sliding window 기법을 사용할 수 있다. 새 값을 계산할 때 과거에 계싼한 결과가 저부 필요한 것이 아니라 일부부난이 필요할 때 써먹을 수 있다.

번갈아서 무언갈 해야할 때 모듈러 연산이 유용하게 사용된다.

지니어스 다시 읽어보기.

## 10. 탐욕법

정당성 증면 - 탐욕적 선택 속성(greedy choice property) + 최적 부분 구조(optimal substructure)

그리디 증명에서 우리가 선택한 방법을 포함하는 최적해가 있음을 증명하기 위해, 우선 우리가 선택한 방법을 포함하지 않는 최적회의 존재를 가정한다. 그리고 이것을 적절히 조작해 우리가 선택한 방법을 포함하는 최적해를 만들어낸다.

!@10/pairSort.cpp@!

허프만 코드도 그리디 알고리즘의 한 종류이다.

미아스 아노르 다시 읽어보기.

## 11. 조합 탐색

가지치기(pruning) 기법 / 좋은 답을 빨리 찾아내기 기법

map에 접근하는 비용은 원소의 수가 커지면 커질수록 늘어나므로, 남은 도시의 수별로 map을 나누면 접근하는 데 드는 시간을 조금이나마 줄이는 효과가 있습니다.

\_\_builtin_popcount();

!@11/bitset.cpp@!

[Integer programming](https://en.wikipedia.org/wiki/Integer_programming)

[Linear programming](https://en.wikipedia.org/wiki/Linear_programming)

(a, b)를 90도 시계방향 회전시키면?

!@11/resize.cpp@!

집합 덮개 문제(set cover)는 전산학과 복잡도 이론에서 다루는 오랜 문제로, 어떠한 전체집합과 그 집합의 부분집합들이 주어졌을 때, 부분집합들 중에서 가능한 한 적은 집합을 골라서 그 집합들의 합집합이 원래 전체집합이 되도록, 즉 그 집합들이 원래 전제집합을 '덮도록' 집합을 선택하는 문제이다.

그리디하게 안되는 이유는~?

```
xxxxxxxx
ooooo
oooo
   oooo
ooo     o
```

특정한 제약에 해당하는 답을 찾는 문제들을 제약 충족 문제(Constraint Satisfaction Problem)이라 부른다.

제약 충족 문제를 해결하는 조합 탐색 알고리즘에서는 두가지를 신경쓴다. 답의 일부를 생성하면 문제의 조건에 의해 다른 조각의 답에 대해 알게 되는 것을 제약 전파(constraint propagation)라 한다. 변수 순서 정하기(variable ordering)은 어느 빈 칸부터, 값 순서 정하기(value ordering)은 어떤 값부터 채울지 정하는 것.

코드 11.12는 비트마스트 배우고 다시 읽어보기. 그나저나 이전 챕터에서 O(n^2)에서 최적화할 수 있는데 그건 너가 알아보라고 한 부분 있었던거 같은데,,

시간나면 '더 읽을거리' 부분도 읽어보자.

## 12. 최적화 문제 결정 문제로 바꿔 풀기

결정문제는 두 가지 답만 있다. 결정문제가 최적화문제보다 어려울 수는 없다.

이분법을 쓰려면 범위를 두 부류로 나눌 수 있어야한다.

1. "가장 좋은 답은 무엇인가?"라는 최적화 문제를 "x 혹은 그보다 좋은 답이 있는가?"라는 결정 문제 형태로 바꾼다.
2. 결정 문제를 쉽게 풀 수 있는 방법이 있는지 찾아본다.
3. 결정 문제를 내부적으로 이용하는 이분법 알고리즘을 작성한다.

이분법 배우고 코드 12.1 다시 읽어보기.

고정된 수의 후보만을 탐색하는 이분법에서는 수치적 오차가 생기면 정답보다 작은 후보로 값이 바뀌어서 안된다. 실수범위에서 탐색하면 정답으로 수렴함.

## 13. 수치 해석

수치 해석(numerical analysis)은 직접 풀기 힘든 수학 문제를 근사적으로 푸는 알고리즘과 이들의 수치적 안정성, 오차의 범위 등을 연구하는 전산학의 한 분야이다.

!@13/e.cpp@!

절대 오차는 값의 크기가 커지면 문제가 생길 수 있다. 부동소수점은 숫자의 절대값이 커질수록 표현할 수 있는 수가 듬성듬성해진다.

!@13/bad.cpp@!

반복문을 100번 수행하면 답의 절대 오차는 최대 |lo-hi|/2^101이 된다. 2^101은 약 31자리 수로 |hi-lo|가 10^20 미만의 수면 이 오차는 항상 10^-7보다 작다.

한 개의 지역 극대점이 있고, 그 이전에는 순증가, 이후에는 순감소하면 삼분 검색을 통해 극점을 찾아낼 수 있다.

```cpp
double f(double x);

double ternary(double lo, double hi) {
    for (int iter=0; iter<100;iter++) {
        double a = (2*lo+hi)/3.0;
        double b = (lo+2*hi)/3.0;
        if (f(a) > f(b))
            hi = b;
        else
            lo = a;
    }
    return (lo+hi)/2.0;
}
```

볼록함수는 그래프 상의 서로 다른 두 점을 직선으로 이었을 때 이 직선이 그래프 밑으로 내려가는 일이 없다. 볼록함수(convex function), 오목함수(concave function).

-볼록 = 오목, 볼록 + 볼록 = 볼록, 볼록 \* c = 볼록.

선형함수는 볼록함수이면서 오목함수이다.

다각형을 수직선으로 잘랐을 떄 최대 길이 부분은 항상 꼭지점을 지난다. 귀류법으로 증명 가능.

심슨 방법. 주어진 구간의 함수를 2차 함수로 근사해서 적분한다.

꽃가루 다시 읽어보기.

이분법 정수로 하니까 안됨,, 공유기 문제

## 14. 정수론

[AKS primality test](https://en.wikipedia.org/wiki/AKS_primality_test)

```cpp
bool isPrime(int n) {
    if (n <= 1) return false;
    if (n == 2) return true;
    if (n % 2 == 0) return false;

    int sqrtn = int(sqrt(n));
    for (int div=3; div <= sqrtn; div += 2)
        if (n % div == 0)
            return false;
    return true;
}
```

```cpp
vector<int> factorSimple(int n) {
    vector<int> ret;
    int sqrtn = int(sqrt(n));
    // 미리 소수를 구해놓으면 더 빠르게 할 수 있다.
    for (int div = 2; div <= sqrtn; ++div)
        while (n % div == 0) {
            n /= div;
            ret.push_back(div);
        }
    if (n > 1) ret.push_back(n); // 소수인 경우인듯
    return ret;
}
```

```cpp
int n;
bool isPrime[MAX_N+1];

void eratosthenes() {
    memset(isPrime, 1, sizeof(isPrime));
    isPrime[0] = isPrime[1] = false;
    int sqrtn = int(sqrt(n));
    for (int i=2; i<=sqrtn; i++)
        if (isPrime[i])
            for (int i*i; j<=n; j+=i)
                isPrime[j] = false;
}
```

체를 만들 때 가장 작은 소인수를 기록해두면 일정 범위의 수에 대한 소인수분해를 빠르게 할 수 있다.

유클리드 알고리즘은 p, q(p>q)의 공약수의 집합이 p-q와 q의 공약수 집합과 같다는 점을 이용한다.

```cpp
// 원래는 뺄셈이지만 모듈러 연산으로 최적화할 수 있다.
int gcd(int p, int q) {
    if (q == 0) return p;
    return gcd(q, p%q);
}
```

마법의 약 다시 읽기.

모듈러 연산에서의 나눗셈 a/b는 b로 나누는 대신 b의 곱셈 역원(multiplicative inverse)을 곱하는 방식으로 이루어진다. 곱셈 역원은 b와 M이 서로소일 때만 존재한다(나누어 떨어지지 않는다 느낌?).

페르마의 소정리를 이용하면, M의 소수일 때 b의 역원 modInv(b, M) = b^(M-2)%M.

(a/b)%M = (a\*modInv(b, M))%M

M이 소수가 아닐 때도 궁금하면 다음 식을 만족하는 A를 찾는다.

A\*b+B\*M === 1 (mod M).

이와 같은 형태의 식을 디오판틴 방정식이라 하며 확장 유클리드 알고리즘으로 풀 수 있다.

유클리드 알고리즘은 한 수에서 다른 수를 빼기를 반복하기에 출현하는 모든 수를 a\*p+b\*q로 표현할 수 있다. 최대공약수와 함께 a, b를 반환하는 알고리즘을 확장 유클리드 알고리즘이라 한다.

확장 유클리드 알고리즘, 중국인 나머지 정리, 루카스의 정리 생략

## 15. 계산 기하

!@15/hypot.cpp@!

[Why are there no asin2() and acos2() functions similar to atan2()?](https://stackoverflow.com/questions/29094261/why-are-there-no-asin2-and-acos2-functions-similar-to-atan2)

```cpp
double polar() const {
    // double atan2(double y, double x);
    // returns [-PI, PI]
    return fmod(atan2(y, x) + 2*PI, 2*PI);
}

vector2 project(const vector2& rhs) const {
    vector2 r = rhs.normalize();
    return r * r.dot(*this);
}
```

내적으로 벡터의 사이각이나 직각 여부, 사영을 알아낼 수 있다.

벡터의 외적은 두 벡터에 모두 수직인 다른 벡터를 반환한다. a X b = ax\*by - ay\*bx = |a||b|sinx. 두 벡터가 이루는 평행사변형의 넓이이다. 외적의 부호는 각도의 부호와 같다. a에서 b로 반시계방향. 극각도를 사용하는 방법보다 속도도 빠르고 수치적으로 안정하며 코드도 간결하다.

```cpp
bool lineIntersection(vector2 a, vector2 b, vector2 c, vector2 d, vector2& x) {
    double det = (b - a).cross(d - c);
    if (fabs(det) < EPSILON) return false;
    x = a + (b - a) * ((c - a).cross(d - c) / det);
    return true;
}
```

선분의 교차 판별은 두 선분이 한 직선 위에 있을 때를 주의해야한다.

```cpp
// (a, b), (c, d)가 평행한 두 선분일 때 이들이 한 점에서 겹치는지 확인.
bool parallelSegments(vector2 a, vector2 b, vector2 c, vector2 d, vector2& p) {
    if (b < a) swap(a, b);
    if (d < c) swap(c, d);

    // 한 직선 위에 없거나 두 선분이 겹치지 않는 경우 거르기
    if (ccw(a, b, c) != 0 || b < c || d < a) return false;
    // 교차점 찾기
    if (a < c) p = c; else p = a;
    return true;
}

// p가 (a, b)를 감싸면서 각 변이 x, y축에 평행한 최소 사각형 내부에 있는지 확인
// a, b, p는 일직선상에 있다고 가정
bool inBoundingRectangle(vector2 p, vector2 a, vector2 b) {
    if (b < a) swap(a, b);
    return p == a || p == b || (a < p && p < b);
}

bool segmentIntersection(vector2 a, vector2 b, vector2 c, vector2 d, vector2& p) {
    if (!lineIntersection(a, b, c, d, p))
        return parallelSegments(a, b, c, d, p);
    return inBoundingRectangle(p, a, b) && inBoundingRectangle(p, c, d);
}
```

```cpp
bool segmentIntersects(vector2 a, vector2 b, vector2 c, vector2 d) {
    double ab = ccw(a, b, c) * ccw(a, b, d);
    double cd = ccw(c, d, a) * ccw(c, d, b);
    // 두 선분이 한 직선 위에 있거나 끝점이 겹치는 경우
    if (ab == 0 && cd == 0) {
        if (b < a) swap(a, b);
        if (d < c) swap(c, d);
        return !(b < c || d < a);
    }
    return ab <= 0 && cd <= 0;
}
```

```cpp
vector2 perependicularFoot(vector2 p, vector2 a, vector2 b) {
    return a + (p - a).project(b - a);
}

double pointToLine(vector2 p, vector2 a, vector2 b) {
    return (p - perpendicularFoot(p, a, b)).norm();
}
```

두 선분을 잇는 가장 가까운 선분은 최소한 두 선분 중 하나의 끝점에서 시작한다.

와 여기는 다시 읽어보자.

기하 알고리즘의 디자인 패턴 - 평면 스위핑 / 회전하는 캘리퍼스

## 16. 비트마스크

!@16/errors.cpp@!

```cpp
// 원소의 토글
toppings ^= (1 << p);

// 가장 낮은 비트
// 나중에 펜윅트리에서 써먹음
int firstTopping = (topping & -toppings);

// 최소 원소 지우기
// 이 짓을 하고 0이면 2의 거듭제곱
topppings &= (toppings - 1);

// 모든 부분 집합 순회하기
for (int subset=pizza; subset; subset = ((subset-1) & pizza)) {
    // pizza = 1101
    // subset
    // 1101
    // 1100
    // 1001
    // 1000
    // 0101
    // 0100
    // 0001
}
```

O(1)의 우선순위 큐를 만들 수 있다.

## 17. 부분합

부분 합을 통해 분산도 계산할 수 있다.

## 18. 선형 자료 구조

[list::splice](https://cplusplus.com/reference/list/list/splice/)

```cpp
void deleteNode(ListNode* node) {
    node->prev->next = node->next;
    node->next->prev = node->prev;
}

void recoverNode(ListNode* node) {
    node->prev->next = node;
    node->next->prev = node;
}
```

Dancing links.

STL에서 list의 크기를 구하는 연산은 O(N)이다.

요세푸스 O(n)에 풀기.

## 19. 큐와 스택, 데크

스택을 이용한 울타리 문제 해법 읽어보기.

삽입 정렬은 온라인 알고리즘, 선택 정렬은 오프라인 알고리즘.

```cpp
int ret = 0, tail = 0, rangeSum = signal[0];
for (int head = 0; head < signals.size(); head++) {
    while (rangeSum < k && tail + 1 < signals.size())
        rangeSum += signals[++tail];
    if (rangeSum == k) ret++;
    rangeSum -= signal[head];
}
return ret;
```

## 20. 문자열

string::find / complexity / Unspecified, but generally up to linear in length()-pos times the length of the sequence to match (worst case).

KMP(Knuth-Morris-Pratt).

시작 위치 i+k에서 답을 찾을 수 있으려면 N[...matched-1]의 길이 matched-k인 접두사와 접미사가 같아야한다. 여기서 접미사 접두사는 자기자신과는 달라야되는듯.

pi[i] = N[...i]의 접두사도 되고 접미사도 되는 문자열의 최대 길이. pi를 부분 일치 테이블(partial match table) 혹은 failure function이라 한다.

KMP 꼴보기 싫어서 '재하의 금고' 문제는 다음에 읽어보자.

```cpp
vector<int> getPartialMatch(const string& N) {
    int n = N.size();
    vector<int> pi(n, 0);

    int matched = 0;
    for (int i = 1; i < n; i++) {
        while (matched > 0 && N[i] != N[matched])
            matched = pi[matched - 1];
        if (N[i] == N[matched]) {
            ++matched;
            pi[i] = matched;
        }
    }

    return pi;
}

vector<int> kmpSearch(const string& H, const string& N) {
    int match = 0;
    auto ret = vector<int>();
    auto pi = getPartialMatch(N);

    for (int i = 0; i < H.size(); i++) {
        while (match > 0 && H[i] != N[match])
            match = pi[match - 1];
        if (H[i] == N[match]) {
            match++;
            if (match == N.size()) {
                ret.push_back(i - N.size() + 1);
                match = pi[match - 1];
            }
        }
    }

    return ret;
}
```

## 21. 트리의 구현과 순회

깊이: 어떤 노드에 도달하기 위한 간선의 수 / 높이: 가장 깊숙히 있는 노드의 깊이

## 22. 이진 검색 트리

대부분의 표준 라이브러리에서 제공하는 이진 검색 트리의 구현도 내부적으로는 대개 레드-블랙 트리를 사용한다.

트립은 부모의 우선순위가 자식의 우선순위보다 높은 이진 검색 트리를 만든다. tree + heap = treap.

!@22/treap.cpp@!

## 23. 우선순위 큐와 힙

배열을 힙으로 O(N)에 변환시킬 수 있지만 어차피 꺼낼 때 O(NlgN)이라서 큰 의미는 없다.

힙 정렬은 병합 정렬과 달리 추가적인 메모리를 요구하지 않고 최악의 경우에도 O(NlgN)이라 좋다.

이미 힙에 들어있는 원소 중 하나를 증가시키는 것도 각 원소의 위치를 별도의 배열에 저장하면 가능하다.

## 24. 구간 트리

일반적으로 이야기하는 구간 트리는 1차원 좌표 상의 국나들을 지정하고 특정 위치를 포함하는 구간들을 찾는 자료 구조로, 책에서 사용하는 프로그래밍 대회 커뮤니티에서 통용되는 구간 트리의 정의와는 다르니 주의.

RMQ(range minimum query): 구간 최소 쿼리, 특정 구간의 최소치를 찾는 문제.

-1을 곱하면 RMQ로 최대 쿼리도 할 수 있다.

족보 탐험, 펜윅 트리 다음에 읽어보기.

## 25. 상호 배타적 집합

공통 원소가 없는, 즉 상호 배타적인 부분 집합들로 나눠진 원소들에 대한 정보를 저장하고 조작하는 자료 구조가 union-find이다.

집합과 트리의 루트는 1:1 대응임을 이용한다.

> ...We close this section with an analysis of union–find with path compression but without union by rank...
>
> The union-find datastructure with path compression but without union by rank processes m find and n-1 link operations in time O((m+n) log n)

에디터 전쟁 다음에 읽어보기.

아 그냥 그래프부터 볼란다

## 27 그래프의 표현과 정의

다중 그래프(multigraph) / 단순 그래프(simple graph). 두 정점 사이에 존재할 수 있는 간선의 개수에 따른 분류.

루트 없는 트리도 그래프의 일종으로 볼 수 있다. 간선을 통해 두 정점을 잇는 방법이 딸 하나이다.

DAG(Directed Acyclic Graph)는 사이클이 없는 방향 그래프로 작업들 간 상호 의존 관계를 표현할 때 자주 사용된다.

경로 중 한 정점을 최대 한 번만 지나는 경로를 단순 경로(simple path)라 한다.

adjecency list / adjecency matrix. 인접 리스트와 인접 행렬.

sparse graph / dense graph.

작업 간의 의존 관계를 간선으로 표현한 방향 그래프를 의존성 그래프(dependency graph)라 한다.

## 28. 그래프의 깊이 우선 탐색

https://www.acmicpc.net/problem/11403 플로이드 배우고 더 잘 풀어보기

위상 정렬 결과의 정당성은 결과 배열을 훑으며 역방향 간선이 있는지 확인하면 된다.

그래프의 모든 간선을 정확히 한 번씩 지나서 시작점으로 돌아오는 경로를 오일러 서킷이라 한다.

그래프의 모든 정점을 정확히 한 번씩 지나는 경로를 헤밀토니안 경로라고 한다.

현대 그래프 이론에서 경로라고 하면 대개 한 점을 한 번만 지나는 단순 경로를 가리킨다. 오일러 트레일은 한 점을 두 번 이상 지날 수도 있기 때문에 경로 대신 트레일이라 한다.

간선의 분류: 트리 간선(tree edge), 순방향 간선(forward edge), 역방향 간선(back edge), 교차 간선(cross edge). 순방향과 역방향은 DFS 스패닝 트리의 선조 자손 관계에 따른다.

무향 그래프에서는 교차 간선이 있을 수 없으며 순방향과 역방향 간선의 구분이 없다.

발견한 순서인 discover[] 배열을 통해 순방향, 역방향, 교차 간선을 구분할 수 있다. (u, v)를 검사했는데 v가 이미 방문된 상태면, 순방향 간선이면 v는 u보다 늦게 발견되어야하고, 역방향 간선이면 일찍, 교차 간선이면 일찍 발견되어야한다.

v가 u보다 먼저 방문되었을 때 v가 u의 부모인지 아닌지는 dfs(v)의 종료 여부로 판단한다.

```cpp
vector<vector<int>> adj;
vector<int> discovered, finished;
int counter;

void dfs2(int here) {
    discovered[here] = counter++;
    for (auto there: adj[here]) {
        if (!discovered[there]) {
            cout << "tree edge" << endl;
            dfs2(there);
        } else if (discovered[here] < discovered[there]) {
            cout << "forward edge" << endl;
        } else if (finished[there] == 0) {
            cout << "back edge" << endl;
        } else {
            cout << "cross edge" << endl;
        }
    }
    finished[here] = 1;
}
```

무향 그래프에서 절단점을 포함하지 않는 서브그래프를 이중 결합 컴포넌트(biconnected component)라고 한다.

두 정점 u와 v에 대해 양방향으로 가는 경로가 있으면 같은 강결합 컴포넌트(strongly connected components, SCC)에 속한다.

방향 그래프에서 각 SCC 사이를 연결하는 간선들을 모으면 SCC들을 정점으로 하는 DAG를 만들 수 있다.

원 그래프의 정점들을 SCC별로 분리하고 각 SCC를 표현하는 정점들을 갖는 새로운 그래프를 만드는 과정을 그래프의 압축(condensation)이라고 한다.

한 사이클에 속한 정점들은 항상 같은 SCC에 있고, 한 SCC에 속한 두 정점 사이를 잇는 양방향 경로를 합치면 단순 경로는 아닐 수 있지만 두 정점을 포함하는 사이클이 된다.

SCC의 그룹 번호?는 위상 정렬의 역순으로 번호가 매겨진다.

루트 없는 트리에 대한 다음 조건들은 모두 동치이다.

- 정확히 V-1개의 간선이 있다.
- 사이클이 존재하지 않는다.
- 두 정점 사이를 연결하는 단순 경로가 정확히 하나 있다.

CNF(conjunctive normal form, 논리곱 정규형). 모든 수식은 ||로 구성되었고 &&로 연결되어있다.

CNF의 모든 절에 최대 두 개의 변수만이 있으면 2-SAT라 하며 다항 시간에 해결할 수 있다.

변수들의 값에 대한 요구 조건을 표현한 그래프를 함의 그래프(implication graph)라 한다. \

2-SAT 다음에 읽어보기.

## 29. 그래프의 너비 우선 탐색

DFS와 달리 BFS에서는 정점의 발견과 방문이 같지 않다.

BFS spanning tree도 있다. 새 정점을 발견하는 데 사용했던 간선들만을 모은 트리이다. 시작점으로부터 다른 모든 정점까지의 최단 경로를 여기서 찾을 수 있다. parent 배열로 bfs 순회 중에 구할 수 있다.

뒤부분 안읽음

## 30. 최단 경로 알고리즘

음수 사이클을 조심하자.

단일 시작점 알고리즘 / 모든쌍 알고리즘

DFS는 여러 용도로 활용되지만 BFS는 대개 그래프의 최단 경로 문제를 풀기 위해 사용한다.

다익스트라: 정점 검사하는데 O(E), PQ에 넣는데 O(ElgE), 더하면 (ElgE)인데 보통 E < V^2이니 O(ElgV)?? 그냥 E로 쓰면 안됨?

중복 원소를 큐에 넣지 않으면 VlgV에 구현할 수도 있다. 피보나치 힙(큐에 들어있는 원소들의 크기를 조절 가능, 상수 시간 매우 큼)이나 이진 검색 트리를 활용한다.

정점이 적거나 간선이 아주 많으면 PQ 없이 구현한 O(V^2+E)가 낫다??

철인 N종 경기 다시 읽어보기.

벨만-포드: (u, v)를 통해 upper[v]를 감소하는 작업을 (u, v)를 따라 완화(relax)한다고 한다.

그래프에 음수 사이클이 있을 때 최단 거리 문제는 제대로 정의되지 않지만 시작점에서 음수 사이클로 가는 경로가 없으면 상관 없다.

|V||E|

각 정점을 마지막으로 완화시킨 간선들을 모으면 스패닝 트리를 얻을 수 있는데, 해당 간선들은 항상 최단 경로 위에 있다.

s에서 u로의 경로의 유무를 알기 위해서는 upper[u] < INF - (적당히 큰 값)이어야 한다. 음수 사이클이 있을 수도 있기 때문.

음의 사이클이 있다고 모든 경로에서 그곳을 지나는건 아니다.

플로이드 알고리즘의 최적화 - i에서 k로 가는 경로가 실제로 있는지 두 번째 for문 바로 다음에 체크한다?

## 31. 최소 스패닝 트리

스패닝 트리에서 정점들이 꼭 부모-자식으로 연결될 필요는 없다. 루트 없는 트리 그건가?

크루스칼 / 프림

## 32. 네트워크 유량

각 간선이 용량을 갖는 그래프에서 두 정점 사이에 얼마나 많은 '흐름' 혹은 유량을 보낼 수 있는지를 계산하는 문제를 네트워크 유량(network flow) 문제라고 한다.

유량이 시작하는 소스, 도착하는 싱크.

포드-폴커슨 알고리즘.

간선의 용량과 유량의 차이를 잔여 용량(residual capacity)라 하자. 잔여 용량 r(u, v) = c(u, v) - f(u, v). 증가 경로를 통해 흘려보낼 수 있는 유량의 최대값은, 포함된 간선의 잔여 용량 중 가장 작은 값으로 결전된다.

새 유량을 보내는 것과 기존의 유량을 상쇄하는 것은 사실상 같은 연산이다.

최소 컷 최대 유량 정리(Min-cut Max-flow Theorem)은 아주 중요하다. 포드-풀커슨 알고리즘의 정당성 증명과 함께 최대 유량 문제가 최소 컷 문제와 밀접하게 연관되어 있음을 보여준다.

유량 네트워크의 컷이란 소스와 싱크가 각각 다른 집합에 족하도록 그래프의 정점들을 두 개의 집합으로 나눈 것이다.

어떤 컷이든 그 유량은 소스에서 싱크로 가는 유량과 같으며 컷의 용량과 같거나 작다.

이때 네트워크에서 용량이 가장 작은 컷을 찾는 문제를 최소 컷(min cut) 문제라고 한다. 두 컷이 용량과 유량이 같으면 항상 최소 컷이다.

최소 용량 최대 유량 정리는 증가 경로가 존재하지 않는 유량 네크워크에서 용량과 유량이 같은 컷을 찾아내는 방법을 보여준다. 소스에서 잔여 용량이 있는 간선을 통해 갈 수 있는 S와 그렇지 않은 T로 나눈다. 소스는 S, 싱크는 T. S->T 모든 간선의 잔여 용량은 0. 모든 간선에 대해 용량과 유량이 같으므로 최소 컷.

!@32/networkFlow.cpp@!

양과 사용처가 제한된 자원을 효율적으로 분배하는 방법을 찾는 문제는 네트워크 유량 문제의 단골 손님이다.

[Blossom algorithm](https://en.wikipedia.org/wiki/Blossom_algorithm)

정점을 두 그룹으로 나눠서 모든 간선이 서로 다른 그룹의 정점들을 연결하도록 할 수 있는 그래프들을 이분 그래프라고 한다.

## TODO

FFT
