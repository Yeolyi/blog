
[https://cs.fyi/guide/http-in-depth](https://cs.fyi/guide/http-in-depth)

HTTP is a TCP/IP-based application layer communication protocol that standardizes how clients and servers communicate with each other. By application layer protocol, I mean that it's simply an abstraction layer that standardizes how hosts (clients and servers) communicate.

## HTTP/0.9

```
GET /index.html
```

```
(response body)
(connection closed)
```

## HTTP/1.0

- HTTP/1.0 could now deal with other response formats i.e. images, video files, plain text or any other content type as well.
- It added more methods (i.e. POST and HEAD),
- request/response formats got changed,
- HTTP headers got added to both the request and responses,
- status codes were added to identify the response,
- character set support was introduced,
- multi-part types, authorization, caching, content encoding and more was included.

The term "Hyper Text" in HTTP became misnomer.

One of the major drawbacks of HTTP/1.0 were you couldn't have multiple requests per connection. This large number of connections results in a serious performance hit as requiring a new TCP connection imposes a significant performance penalty because of three-way handshake followed by slow-start.

```
GET / HTTP/1.0
Host: cs.fyi
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)
Accept: */*
```

```
HTTP/1.0 200 OK
Content-Type: text/plain
Content-Length: 137582
Expires: Thu, 05 Dec 1997 16:00:00 GMT
Last-Modified: Wed, 5 August 1996 15:55:28 GMT
Server: Apache 0.84
(response body)
(connection closed)
```

## Three-way handshake

SYN / SYN ACK / ACK

Apart from being connectionless, HTTP also is a stateless protocol.

## HTTP/1.1

- New HTTP methods were added
- Hostname Identification required
- Persistent Connections
- Pipelining. Client could send multiple requests to the server without waiting for the response from server on the same connection and server had to send the response in the same sequence in which requests were received.

> It should be noted that in order to benefit from persistent connections or pipelining, Content-Length header must be available on the response, because this would let the client know when the transmission completes and it can send the next request (in normal sequential way of sending requests) or start waiting for the the next response (when pipelining is enabled).

- Chunked Transfers. When the server cannot really find out the Content-Length when the transmission starts, it may start sending the content in pieces (chunk by chunk).
- digest and proxy authentication
- caching, byte ranges, character sets, langauge negotiation, client cookies, enhanced compression support, new status codes...

[Key differences between HTTP=1.0 and HTTP=1.1](https://www.ra.ethz.ch/cdstore/www8/data/2136/pdf/pd1.pdf)

[Original RFC](https://tools.ietf.org/html/rfc2616)

...Well HTTP/1.1 has persistent connections, then why so many connections? you say! The reason is, in HTTP/1.1 it can only have one outstanding connection at any moment of time. HTTP/1.1 tried to fix this by introducing pipelining but it didn't completely address the issue because of the head-of-line blocking where a slow or heavy request may block the requests behind and once a request gets stuck in a pipeline, it will have to wait for the next requests to be fulfilled.

## SPDY - 2009

Google went ahead and started experimenting with alternative protocols.

Bandwidth를 늘리는건 성능 향상의 한도가 있지만, latency의 개선은 꾸준한 성능 향상이 있음이 중심 아이디어.

HTTP/2 is mostly inspired from SPDY.

SPDY didn't really try to replace HTTP; it was a translation layer over HTTP which existed at the application layer and modified the request before sending it over to the wire.

It become a defacto standards.

Google decided to merge it into HTTP while giving birth to HTTP/2 and deprecating SPDY.

## HTTP/2

HTTP/2 was designed for low latency transport of content.

- Binary instead of Textual

Easier to parse. Every HTTP/2 request and response is given a unique stream ID and it is divided into frames. Frames are nothing but binary pieces of data. A collection of frames is called a Stream.

It is worth mentioning that, any request initiated by client uses odd numbers and the response from server has even numbers stream IDs.

Apart from the HEADERS and DATA, another frame type that I think worth mentioning here is RST_STREAM which is a special frame type that is used to abort some stream. HTTP/1.1 시절처럼 서버로부터 수신을 멈추기 위해 연결을 끊고 새로운 연결을 만들어 latency를 늘리는 짓을 하지 않아도 된다.

- Multiplexing - Multiple asynchronous HTTP requests over a single connection

Once a TCP connection is opened, all the streams are sent asynchronously through the same connection without opening any additional connections. And in turn, the server responds in the same asynchronous way i.e. the response has no order and the client uses the assigned stream id to identify the stream to which a specific packet belongs.

- Header compression using HPACK

Unlike request and response, headers are not compressed in gzip or compress etc formats but there is a different mechanism in place for header compression which is literal values are encoded using Huffman code and a headers table is maintained by the client and server and both the client and server omit any repetitive headers (e.g. user agent etc) in the subsequent requests and reference them using the headers table maintained by both.

- Server Push - Multiple responses for single request

Server push is another tremendous feature of HTTP/2 where the server, knowing that the client is going to ask for a certain resource, can push it to the client without even client asking for it.

- Request Prioritization

A client can assign a priority to a stream by including the prioritization information in the HEADERS frame by which a stream is opened.

- Security

Security through TLS is not mandatory, but most vendors stated that they will only support HTTP/2 when it is used over TLS.

[HTTP/2 specs](https://http2.github.io/)
